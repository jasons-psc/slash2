12/16/2011
----------

Background:
-----------

Currently slash2 has two ways of updating attributes:

	- the client can issue a setattr RPC to mds.
	- the i/o server can issue a crc-update RPC, piggybacking size and mtime

To avoid these two RPCs cross path with each other, we have a utimegen mechanism
so that an attribute update is only allowed by the crc-update path if it has the
right generation number (utimegen).  This generation number is stored in the ZFS
layer (zp_s2utimgen) and is bumped each time we update mtime. It only applies
to mtime. 

Using generation number means that the crc-update path has to compete to get the 
right to update the attributes. Instead, we should really update attributes based 
on when the corresponding operation (chmod, write, etc) happened on the client.
Because utimegen only applies to mtime, crc-update path always increases file size, 
which could be a problem as well.  Imagine that a client writes some data to increase 
the file size and then decides to truncate the file size.  The final file size 
could be incorrect.

Another issue with the current mechanism is that the most recent attributes of a
file can be at either mds or ios.  When the fchm (file cache entry) of a client 
needs to be re-established, where does it get attributes from?  The most recent 
attributes might still be en route to mds from IOS.

We could make the current scheme work by adding tricks here and there. But to make
things robust, we need a simpler way.  We will let client be the only one that can
update the attributes.  It should work regardless of network delays and service
outage.

Solution 1
----------

So the idea is that we will treat attribute we do with data.

We need a lease on the attributes just as we have leases on individual bmaps.

So we will make some changes to existing RPCs, and perhaps add some new ones.

	* SRMT_LOOKUP: implicitly grant a shared or exclusive lease on the attributes
	               depending on whether if there is another client working
                       on the same file.  

	* SRMT_SETATTR: We should also send this RPC if we find dirty attributes when 
                        we close a file.

	* SRMT_RELASEBMAP: can piggyback dirty attributes.  No, this RPC goes to the
			   IOS, not mds.

        * SRMT_BMAPDIO: We may be able to extend its meaning to revoke the right of
                        a client to cache attributes exclusively.

We might need a daemon to flush dirty attributes just like we flush bmaps.  Perhaps
we can use the same flush thread that does the latter.

The bottom line is that we need a lease to protect attributes. They are cacheable if
the lease is exclusive.

We maybe able to combine bmap and attribute leases in a RPC:

	* SRMT_RELEASE_LEASE: use type to distinguish whether it is a lease for
                              attributes or bmap.
	* SRMT_REVOKE_LEASE

Solution 2
----------

Instead of going for perfect coherency, we still uses the NFS way of caching attributes 
for a short period of time.  The would save a lot of code complexity and should work well 
in practice.  In addition, perfect coherency is costly to achieve in a wide area network.

Potential Issues:

	* Right now, there is only sliod updating the file size.  In this new scheme, two 
	  clients can do so.

	* The peformance of close() could take a hit, because we want to make sure that 
	  dirty attributes are flushed to mds.

Extra Notes:

	* If the mds knows that more than one client is writing the same file, it should
	  disallow any size decreases.

	* If the mds knows that more than one client is writing the same file, it should
	  advise clients to reduce attributes caching time.

We will go for the second solution.

12/19/2011
----------

We cache all the dirty attribute updates at the client side, including new uid/gid.  The MDS 
just accepts these changes without checking for credentials.
