Index: slash_nara/mount_slash/mount_slash.h
===================================================================
--- slash_nara/mount_slash/mount_slash.h	(revision 20044)
+++ slash_nara/mount_slash/mount_slash.h	(working copy)
@@ -142,7 +142,7 @@
 	struct psc_listentry		  car_lentry;
 	struct pscrpc_async_args	  car_argv;
 	int				(*car_cbf)(struct pscrpc_request *, int,
-						struct pscrpc_async_args *);
+						struct pscrpc_async_args *, int);
 	uint64_t			  car_id;
 	size_t				  car_len;
 	struct msl_fsrqinfo		 *car_fsrqinfo;
@@ -181,10 +181,11 @@
 	struct msl_fhent		*mfsrq_fh;
 	char				*mfsrq_buf;
 	size_t				 mfsrq_size;
+	size_t				 mfsrq_len;
 	off_t				 mfsrq_off;
 	int				 mfsrq_flags;
 	int				 mfsrq_err;
-	int				 mfsrq_ref;	/* # car's needed to satisfy this req */
+	int				 mfsrq_ref;	/* taken by biorq and the thread that does the I/O */
 	int				 mfsrq_reissue;
 	enum rw				 mfsrq_rw;
 	struct pscfs_req		*mfsrq_pfr;
@@ -197,6 +198,7 @@
 #define MFSRQ_DIO			(1 << 3)
 #define MFSRQ_AIOREADY			(1 << 4)
 #define MFSRQ_REISSUED			(1 << 5)
+#define MFSRQ_REPLIED			(1 << 6)
 
 void	msl_fsrqinfo_write(struct msl_fsrqinfo *);
 int	msl_fsrqinfo_state(struct msl_fsrqinfo *, int, int, int);
@@ -205,8 +207,6 @@
 #define msl_fsrqinfo_isset(q, f)	msl_fsrqinfo_state((q), (f), 0, 0)
 #define msl_fsrqinfo_aioisset(q)	msl_fsrqinfo_state((q), MFSRQ_AIOWAIT, 0, 0)
 #define msl_fsrqinfo_aioset(q)		msl_fsrqinfo_state((q), MFSRQ_AIOWAIT, 1, 0)
-#define msl_fsrqinfo_readywait(q)	msl_fsrqinfo_state((q), MFSRQ_READY, 0, 1)
-#define msl_fsrqinfo_readyset(q)	msl_fsrqinfo_state((q), MFSRQ_READY, 1, 1)
 #define msl_fsrqinfo_aioreadywait(q)	msl_fsrqinfo_state((q), MFSRQ_AIOREADY, 0, 1)
 #define msl_fsrqinfo_aioreadyset(q)	msl_fsrqinfo_state((q), MFSRQ_AIOREADY, 1, 1)
 
@@ -246,11 +246,11 @@
 void	 msl_bmpces_fail(struct bmpc_ioreq *);
 void	_msl_biorq_destroy(const struct pfl_callerinfo *, struct bmpc_ioreq *);
 void	 msl_mfh_seterr(struct msl_fhent *);
-int	 msl_dio_cb(struct pscrpc_request *, int, struct pscrpc_async_args *);
+int	 msl_dio_cb(struct pscrpc_request *, int, struct pscrpc_async_args *, int);
 ssize_t	 msl_io(struct pscfs_req *, struct msl_fhent *, char *, size_t, off_t, enum rw);
-int	 msl_read_cb(struct pscrpc_request *, int, struct pscrpc_async_args *);
+int	 msl_read_cb(struct pscrpc_request *, int, struct pscrpc_async_args *, int);
 void	 msl_reada_rpc_launch(struct bmap_pagecache_entry **, int);
-int	 msl_readahead_cb(struct pscrpc_request *, int, struct pscrpc_async_args *);
+int	 msl_readahead_cb(struct pscrpc_request *, int, struct pscrpc_async_args *, int);
 int	 msl_stat(struct fidc_membh *, void *);
 int	 msl_write_rpc_cb(struct pscrpc_request *, struct pscrpc_async_args *);
 
Index: slash_nara/mount_slash/mount_slash_int.c
===================================================================
--- slash_nara/mount_slash/mount_slash_int.c	(revision 20044)
+++ slash_nara/mount_slash/mount_slash_int.c	(working copy)
@@ -64,6 +64,9 @@
 struct timespec		msl_bmap_max_lease = { BMAP_CLI_MAX_LEASE, 0 };
 struct timespec		msl_bmap_timeo_inc = { BMAP_CLI_TIMEO_INC, 0 };
 
+__static size_t msl_pages_copyin(struct bmpc_ioreq *);
+__static void msl_biorq_complete_fsrq(struct bmpc_ioreq *);
+
 struct pscrpc_nbreqset *pndgReadaReqs; /* non-blocking set for RA's */
 
 struct psc_iostats	msl_diord_stat;
@@ -253,19 +256,14 @@
 				    "wait and retry for EIO to clear");
 				psc_assert(e->bmpce_waitq);
 
-				/* XXX: should take a ref before wait */
 				BMPCE_WAIT(e);
 
+				bmpce_release_locked(e, bmpc);
 				BMPC_LOCK(bmpc);
 				goto restart;
 			}
-			/* Increment the ref cnt via the lru mgmt
-			 *   function for all pages needed to
-			 *   fulfill the read and for ra pages
-			 *   which need to be retrieved.
-			 */
-			bmpce_handle_lru_locked(e, bmpc, op, 1);
 			psc_dynarray_add(&r->biorq_pages, e);
+			BMPCE_ULOCK(e);
 
 		} else {
 			DEBUG_BMPCE(PLL_INFO, e, "ra (npndg=%d) i=%d "
@@ -275,17 +273,7 @@
 			    biorq_is_my_bmpce(r, e), mfh->mfh_ra.mra_raoff,
 			    (off_t)(bmpce_off + bmap_foff(b)));
 
-			/* These are read-ahead bmpce's.  Only add
-			 *   pages which have yet to be retrieved.
-			 */
-			if (e->bmpce_flags & BMPCE_EIO) {
-				/*
-				 * Don't bother with RA of pages marked
-				 * EIO.
-				 */
-				DEBUG_BMPCE(PLL_WARN, e, "no RA for EIO");
-
-			} else if (biorq_is_my_bmpce(r, e)) {
+			if (biorq_is_my_bmpce(r, e)) {
 				/* Other threads will block on the reada
 				 *   completion.  The cb handler will decref
 				 *   the bmpce.
@@ -297,7 +285,6 @@
 				 * effect, the cache is no longer mine.
 				 */
 				e->bmpce_owner = b;
-				bmpce_handle_lru_locked(e, bmpc, op, 1);
 				bmap_op_start_type(b, BMAP_OPCNT_READA);
 				/*
 				 * Place the bmpce into our private pll.
@@ -317,25 +304,14 @@
 				} else {
 					MFH_ULOCK(mfh);
 				}
+				BMPCE_ULOCK(e);
+			} else
+				bmpce_release_locked(e, bmpc);
 
-			} else if (e->bmpce_flags & BMPCE_LRU) {
-				/*
-				 * There's no official read op pending
-				 * for this ra page so no read ref is
-				 * taken.  The lru is adjusted in
-				 * preparation for its possible use.
-				 */
-				psc_assert(e->bmpce_flags & BMPCE_DATARDY);
-				PFL_GETTIMESPEC(&e->bmpce_laccess);
-				pll_remove(&bmpc->bmpc_lru, e);
-				pll_add_sorted(&bmpc->bmpc_lru, e,
-				    bmpce_lrusort_cmp1);
-			}
 			MFH_LOCK(mfh);
 			mfh->mfh_ra.mra_raoff = bmap_foff(b) + bmpce_off;
 			MFH_ULOCK(mfh);
 		}
-		BMPCE_ULOCK(e);
 
 		i++;
 
@@ -378,7 +354,6 @@
 			     (rfsz > e->bmpce_off &&
 			      rfsz < e->bmpce_off + BMPC_BLKSZ))) {
 				    e->bmpce_flags |= BMPCE_RBWPAGE;
-				    psc_atomic16_inc(&e->bmpce_rdref);
 				    r->biorq_flags |= BIORQ_RBWFP;
 
 			} else if ((i == (npages - 1) &&
@@ -387,7 +362,6 @@
 				    (rfsz > e->bmpce_off &&
 				     rfsz < e->bmpce_off + BMPC_BLKSZ))) {
 				e->bmpce_flags |= BMPCE_RBWPAGE;
-				psc_atomic16_inc(&e->bmpce_rdref);
 				r->biorq_flags |= BIORQ_RBWLP;
 			}
 		}
@@ -480,82 +454,12 @@
 {
 	struct bmap_pagecache_entry *e;
 	struct bmap_pagecache *bmpc = bmap_2_bmpc(r->biorq_bmap);
-	int i, eio;
+	int i;
 
-	psc_assert(r->biorq_flags & BIORQ_DESTROY);
-	psc_assert(!(r->biorq_flags & (BIORQ_INFL | BIORQ_SCHED)));
-
-	/*
-	 * Block here on any of our EIO'd pages waiting for other
-	 * threads to release their references.
-	 *
-	 * Additionally, we need to block for RA pages which have not
-	 * yet been marked as EIO.
-	 */
-	DYNARRAY_FOREACH(e, i, &r->biorq_pages) {
-		BMPCE_LOCK(e);
-
-		if (biorq_is_my_bmpce(r, e) &&
-		    (r->biorq_flags & BIORQ_RBWFAIL)) {
-			/*
-			 * BIORQ_RBWFAIL is set in msl_io when the page
-			 * failed to be faulted from the IOS.  Fail
-			 * these here to ensure that we don't move to
-			 * the LRU without DATARDY EIO set.
-			 */
-			e->bmpce_flags |= BMPCE_EIO;
-			DEBUG_BMPCE(PLL_WARN, e, "set BMPCE_EIO");
-		}
-
-		if (biorq_is_my_bmpce(r, e) && (e->bmpce_flags & BMPCE_EIO)) {
-			if ((r->biorq_flags & BIORQ_RBWFAIL) &&
-			    (e->bmpce_flags & BMPCE_RBWPAGE)) {
-				psc_assert(r->biorq_flags & BIORQ_WRITE);
-				psc_assert(psc_atomic16_read(
-				    &e->bmpce_wrref) >= 1);
-				psc_assert(psc_atomic16_read(
-				    &e->bmpce_rdref) >= 1);
-			}
-
-			while (((r->biorq_flags & BIORQ_RBWFAIL) ?
-				psc_atomic16_read(&e->bmpce_wrref) > 1 :
-				psc_atomic16_read(&e->bmpce_wrref)) ||
-			       psc_atomic16_read(&e->bmpce_rdref) > 1) {
-				BMPCE_WAIT(e);
-				BMPCE_LOCK(e);
-			}
-			/*
-			 * Unless this is an RBWFAIL, only my rd ref
-			 * should remain.
-			 */
-			psc_assert((psc_atomic16_read(&e->bmpce_wrref) ==
-				    !!(r->biorq_flags & BIORQ_RBWFAIL)));
-
-			if (r->biorq_flags & BIORQ_RBWFAIL &&
-			    (e->bmpce_flags & BMPCE_RBWPAGE)) {
-				psc_assert(psc_atomic16_read(&e->bmpce_rdref) == 1);
-				psc_atomic16_dec(&e->bmpce_rdref);
-			}
-		}
-
-		e->bmpce_flags &= ~BMPCE_INFLIGHT;
-		DEBUG_BMPCE(PLL_INFO, e, "unset inflight");
-		BMPCE_ULOCK(e);
-	}
-
 	BMPC_LOCK(bmpc);
 	DYNARRAY_FOREACH(e, i, &r->biorq_pages) {
-		/*
-		 * bmpce with no reference will be freed by the reaper.
-		 */
 		BMPCE_LOCK(e);
-		eio = (e->bmpce_flags & BMPCE_EIO) ? 1 : 0;
-		bmpce_handle_lru_locked(e, bmpc,
-		    (r->biorq_flags & BIORQ_WRITE) ?
-		    BIORQ_WRITE : BIORQ_READ, 0);
-
-		if (!eio)
-			BMPCE_ULOCK(e);
+		bmpce_release_locked(e, bmpc);
 	}
 	BMPC_ULOCK(bmpc);
 }
@@ -565,16 +469,25 @@
     struct bmpc_ioreq *r)
 {
 	struct msl_fhent *f = r->biorq_fhent;
+
 #if FHENT_EARLY_RELEASE
 	int fhent = 1;
 #endif
 
 	BIORQ_LOCK(r);
 
+	r->biorq_ref--;
+	psc_assert(r->biorq_ref >= 0);
+	DEBUG_BIORQ(PLL_INFO, r, "destroying (ref=%d)", r->biorq_ref);
+	if (r->biorq_ref) {
+		BIORQ_ULOCK(r);
+		return;
+	}
 	psc_assert(!(r->biorq_flags & BIORQ_DESTROY));
+	r->biorq_flags |= BIORQ_DESTROY;
+	BIORQ_ULOCK(r);
 
 	OPSTAT_INCR(SLC_OPST_BIORQ_DESTROY);
-
 	/*
 	 * Reads req's have their BIORQ_SCHED and BIORQ_INFL flags
 	 * cleared in msl_read_cb to unblock waiting threads at the
@@ -603,13 +516,11 @@
 			    (BIORQ_INFL | BIORQ_SCHED)));
 	}
 
-	r->biorq_flags |= BIORQ_DESTROY;
 
 #if FHENT_EARLY_RELEASE
 	if (r->biorq_flags & BIORQ_NOFHENT)
 		fhent = 0;
 #endif
-	BIORQ_ULOCK(r);
 
 	DEBUG_BIORQ(PLL_INFO, r, "destroying (nwaiters=%d)",
 		    atomic_read(&r->biorq_waitq.wq_nwaiters));
@@ -700,67 +611,41 @@
 	return (NULL);
 }
 
-__static int
-msl_biorq_aio_decref(struct bmpc_ioreq *r)
-{
-	struct msl_fsrqinfo *q = r->biorq_fsrqi;
-	int rc;
+#define msl_fsrq_aiowait_tryadd_locked(e,r) \
+	_msl_fsrq_aiowait_tryadd_locked(e,r, __LINE__)
 
-	psc_assert(q);
-	psc_assert(r->biorq_flags & BIORQ_AIOWAIT);
-
-	MFH_LOCK(r->biorq_fhent);
-	rc = --q->mfsrq_ref;
-	MFH_ULOCK(r->biorq_fhent);
-
-	DEBUG_BIORQ(PLL_WARN, r, "q=%p (mfsrq_ref=%d)", q, rc);
-
-	psc_assert(rc >= 0);
-
-	return (rc);
-}
-
 __static void
-msl_biorq_aio_prep(struct bmpc_ioreq *r)
+_msl_fsrq_aiowait_tryadd_locked(struct bmap_pagecache_entry *e,
+    struct bmpc_ioreq *r, int line)
 {
-	struct msl_fsrqinfo *q = r->biorq_fsrqi;
-	int cnt = 0;
-
-	psc_assert(q);
-
-	BIORQ_LOCK(r);
-	r->biorq_flags |= BIORQ_AIOWAIT;
-	BIORQ_ULOCK(r);
-
-	MFH_LOCK(r->biorq_fhent);
-	if (!(q->mfsrq_flags & MFSRQ_REISSUED))
-		cnt = ++q->mfsrq_ref;
-	MFH_ULOCK(r->biorq_fhent);
-
-	DEBUG_BIORQ(PLL_WARN, r, "q=%p (mfsrq_ref=%d)", q, cnt);
-}
-
-__static void
-msl_fsrq_aiowait_tryadd_locked(struct bmap_pagecache_entry *e,
-    struct bmpc_ioreq *r)
-{
 	int locked;
 
 	LOCK_ENSURE(&e->bmpce_lock);
 
 	psc_assert(!(e->bmpce_flags & BMPCE_DATARDY));
 	locked = MFH_RLOCK(r->biorq_fhent);
+#if 0
 	if (!msl_fsrqinfo_isset(r->biorq_fsrqi, MFSRQ_BMPCEATT)) {
 		r->biorq_fsrqi->mfsrq_flags |= MFSRQ_BMPCEATT;
 		r->biorq_fsrqi->mfsrq_bmpceatt = e;
 		pll_add(&e->bmpce_pndgaios, r->biorq_fsrqi);
 	}
+#endif
+	BIORQ_LOCK(r);
+	if (!(r->biorq_flags & BIORQ_WAIT)) {
+		r->biorq_ref++;
+		r->biorq_flags |= BIORQ_WAIT;
+		DEBUG_BIORQ(PLL_INFO, r, "biorq pending (e=%p, line=%d)", e, line);
+		pll_add(&e->bmpce_pndgaios, r);
+	}
+	BIORQ_ULOCK(r);
+	
 	MFH_URLOCK(r->biorq_fhent, locked);
 }
 
 __static int
 msl_req_aio_add(struct pscrpc_request *rq,
-    int (*cbf)(struct pscrpc_request *, int, struct pscrpc_async_args *),
+    int (*cbf)(struct pscrpc_request *, int, struct pscrpc_async_args *, int),
     struct pscrpc_async_args *av)
 {
 	struct bmpc_ioreq *r = av->pointer_arg[MSL_CBARG_BIORQ];
@@ -807,9 +692,11 @@
 				continue;
 
 			}
+#if 0
 			/* XXX avoid this if the biorq is the owner */
 			if (!naio)
 				msl_fsrq_aiowait_tryadd_locked(e, r);
+#endif
 
 			BMPCE_SETATTR(e, BMPCE_AIOWAIT, "set aio, r=%p", r);
 			BMPCE_ULOCK(e);
@@ -817,12 +704,15 @@
 		}
 		/* Should have found at least one aio'd page. */
 		psc_assert(naio);
-		msl_biorq_aio_prep(r);
+		/*
+		 * XXX do we need this?
+		 */
+		//msl_biorq_aio_prep(r);
 		car->car_fsrqinfo = r->biorq_fsrqi;
 
 	} else if (cbf == msl_dio_cb) {
 		OPSTAT_INCR(SLC_OPST_DIO_CB_ADD);
-		msl_biorq_aio_prep(r);
+		//msl_biorq_aio_prep(r);
 		if (r->biorq_flags & BIORQ_WRITE)
 			av->pointer_arg[MSL_CBARG_BIORQ] = NULL;
 
@@ -840,39 +730,55 @@
 }
 
 __static void
-msl_fsrq_complete(struct msl_fsrqinfo *q)
+msl_complete_fsrq(struct msl_fsrqinfo *q)
 {
+	MFH_LOCK(q->mfsrq_fh);
+	q->mfsrq_ref--;
+	if (q->mfsrq_ref) {
+		MFH_ULOCK(q->mfsrq_fh);
+		return;
+	}
+	MFH_ULOCK(q->mfsrq_fh);
+	if (q->mfsrq_rw == SL_READ) {
+		pscfs_reply_read(q->mfsrq_pfr, q->mfsrq_buf, 
+			q->mfsrq_len, -abs(q->mfsrq_err));
+		OPSTAT_INCR(SLC_OPST_FSRQ_READ_FREE);
+	} else {
+		pscfs_reply_write(q->mfsrq_pfr, 
+			q->mfsrq_len, -abs(q->mfsrq_err));
+		OPSTAT_INCR(SLC_OPST_FSRQ_WRITE_FREE);
+	}
+}
+
+__static void
+msl_biorq_complete_fsrq(struct bmpc_ioreq *r0)
+{
+	struct msl_fsrqinfo *q;
 	struct bmpc_ioreq *r;
 	size_t len, rc;
-	int i;
+	int i, found = 0;
 
-	psc_assert(!q->mfsrq_ref);
+	q = r0->biorq_fsrqi;
 
+	psclog_info("biorq = %p, fsrq = %p, pfr = %p", r0, q, q->mfsrq_pfr);
+
 	for (i = 0, len = 0; i < MAX_BMAPS_REQ; i++) {
 		r = q->mfsrq_biorq[i];
 
-		if (!r || r == MSL_BIORQ_COMPLETE ||
-		    !(r->biorq_flags & BIORQ_AIOWAIT))
+		/* only complete myself */
+		if (r != r0) 
 			continue;
+	
+		found = 1;
 
 		BIORQ_LOCK(r);
 		r->biorq_flags &= ~(BIORQ_INFL | BIORQ_SCHED);
 		r->biorq_flags &= ~(BIORQ_RBWLP | BIORQ_RBWFP);
 		BIORQ_ULOCK(r);
-
-		DEBUG_BIORQ(PLL_WARN, r, "fsrq_complete q=%p err=%d",
-		    q, q->mfsrq_err);
-
-		if (q->mfsrq_rw != SL_READ)
-			abort();
-
-		psc_assert(r->biorq_flags & BIORQ_READ);
-
-		if (q->mfsrq_err) {
-			msl_biorq_destroy(r);
-			continue;
-		}
-
+	
+		/*
+ 		 * copy data in and out on behand of the finishing biorq.
+ 		 */
 		if (i && !len)
 			/*
 			 * This fsrq has 2 biorqs (probably spanned two
@@ -880,7 +786,7 @@
 			 * cache so interpolate its len.
 			 */
 			len = q->mfsrq_size - r->biorq_len;
-
+	
 		if (r->biorq_flags & BIORQ_DIO) {
 			/*
 			 * Support mix of dio and cached reads.  This
@@ -889,116 +795,64 @@
 			 * the tail of the file in msl_io().
 			 */
 			len += r->biorq_len;
-			msl_biorq_destroy(r);
 		} else {
-			rc = msl_pages_copyout(r);
+			if (q->mfsrq_rw == SL_READ)
+				rc = msl_pages_copyout(r);
+			else
+				rc = msl_pages_copyin(r);
 			if (!rc)
 				break;
 			len += rc;
 			psc_assert(len <= q->mfsrq_size);
 		}
 	}
+	if (!found)
+		psc_fatalx("Missing biorq %p in fsrq %p\n", r0, q);
 
+	MFH_LOCK(q->mfsrq_fh);
 	if (!q->mfsrq_err) {
-		MFH_LOCK(q->mfsrq_fh);
-		q->mfsrq_fh->mfh_nbytes_rd += len;
-		MFH_ULOCK(q->mfsrq_fh);
+		q->mfsrq_len += len;
+		if (q->mfsrq_rw == SL_READ)
+			q->mfsrq_fh->mfh_nbytes_rd += len;
+		else
+			q->mfsrq_fh->mfh_nbytes_wr += len;
 	}
+	MFH_ULOCK(q->mfsrq_fh);
 
-	pscfs_reply_read(q->mfsrq_pfr, q->mfsrq_buf, len,
-	    -abs(q->mfsrq_err));
-	OPSTAT_INCR(SLC_OPST_FSRQ_READ_FREE);
+	msl_complete_fsrq(q);
 }
 
 __static void
-msl_fsrq_completion_try(struct msl_fsrqinfo *q)
+msl_bmpce_complete_biorq(struct bmap_pagecache_entry *e0)
 {
+	int i;
 	struct bmpc_ioreq *r;
 	struct bmap_pagecache_entry *e;
-	int i, j, aio_done = 0;
 
-	psc_assert(q);
-
-	/*
-	 * Read-ahead completions need to barrier here or else risk
-	 * finishing before msl_io() is ready.
-	 */
-	msl_fsrqinfo_readywait(q);
-
-	/*
-	 * Scan through the biorq's and their bmpce's for pages still
-	 * blocked in AIOWAIT.
-	 */
-	for (i = 0; i < MAX_BMAPS_REQ; i++) {
-		r = q->mfsrq_biorq[i];
-		if (!r) {
-			psc_assert(i);
-			break;
-		}
-
-		if (r == MSL_BIORQ_COMPLETE ||
-		    !(r->biorq_flags & BIORQ_AIOWAIT))
-			continue;
-
-		aio_done = 1;
-
-		DYNARRAY_FOREACH(e, j, &r->biorq_pages) {
+	/* 
+	 * The owning request of the cache entry should not be on its
+	 * own pending list, so it should not go away in the process.
+	 */ 
+	while ((r = pll_get(&e0->bmpce_pndgaios))) {
+		BIORQ_LOCK(r);
+		r->biorq_flags &= ~BIORQ_WAIT;
+		BIORQ_ULOCK(r);
+		DYNARRAY_FOREACH(e, i, &r->biorq_pages) {
 			BMPCE_LOCK(e);
-			if (e->bmpce_flags & BMPCE_EIO) {
-				BMPCE_ULOCK(e);
-
-				MFH_LOCK(r->biorq_fhent);
-				q->mfsrq_err = EIO;
-				MFH_ULOCK(r->biorq_fhent);
-
-				/* XXX shouldn't we check all pages? */
-				goto out;
-
-			} else if (!(e->bmpce_flags & BMPCE_DATARDY)) {
-				MFH_LOCK(r->biorq_fhent);
-				psc_assert(msl_fsrqinfo_isset(r->biorq_fsrqi,
-				    MFSRQ_BMPCEATT));
-				r->biorq_fsrqi->mfsrq_flags &= ~MFSRQ_BMPCEATT;
-				r->biorq_fsrqi->mfsrq_bmpceatt = NULL;
+			if (!(e->bmpce_flags & BMPCE_EIO) &&
+			    !(e->bmpce_flags & BMPCE_DATARDY)) {
 				msl_fsrq_aiowait_tryadd_locked(e, r);
-				MFH_ULOCK(r->biorq_fhent);
+				DEBUG_BIORQ(PLL_NOTIFY, r, 
+					"still blocked on (bmpce@%p)", e);
 				BMPCE_ULOCK(e);
-				DEBUG_BIORQ(PLL_NOTIFY, r,
-				    "still blocked on (bmpce@%p)", e);
-				return;
-			}
-			BMPCE_ULOCK(e);
+				break;
+			} else
+				BMPCE_ULOCK(e);
 		}
+		msl_biorq_destroy(r);
 	}
- out:
-	psc_assert(aio_done);
-
-	msl_fsrq_complete(q);
 }
 
-__static void
-msl_bmpce_aio_process(struct bmap_pagecache_entry *e)
-{
-	struct msl_fsrqinfo *q;
-	struct psc_dynarray a = DYNARRAY_INIT;
-	int i;
-
-	/* If fsrq cannot be completed. msl_fsrq_completion_try()
-	 * will reattach it to another aio'd bmpce.
-	 */
-	while ((q = pll_get(&e->bmpce_pndgaios)))
-		/* msl_fsrq_completion_try() may remove 'e' so loop
-		 * gather work before calling msl_fsrq_completion_try().
-		 */
-		psc_dynarray_add(&a, q);
-
-	DYNARRAY_FOREACH(q, i, &a) {
-		msl_fsrq_completion_try(q);
-	}
-
-	psc_dynarray_free(&a);
-}
-
 #define msl_bmpce_rpc_done(e, rc)					\
 	_msl_bmpce_rpc_done(PFL_CALLERINFOSS(SLSS_BMAP), (e), (rc))
 
@@ -1006,14 +860,9 @@
 _msl_bmpce_rpc_done(const struct pfl_callerinfo *pci,
     struct bmap_pagecache_entry *e, int rc)
 {
-	int aio_completion_try = 0;
-
 	BMPCE_LOCK(e);
 	psc_assert(e->bmpce_waitq);
 
-	if (pll_nitems(&e->bmpce_pndgaios))
-		aio_completion_try = 1;
-
 	if (rc) {
 		e->bmpce_flags |= BMPCE_EIO;
 		DEBUG_BMPCE(PLL_WARN, e, "set BMPCE_EIO");
@@ -1025,20 +874,14 @@
 		 * this is not the best place but should suffice for
 		 * now.
 		 */
-		psc_assert(psc_atomic16_read(&e->bmpce_rdref) >= 1);
-		psc_atomic16_dec(&e->bmpce_rdref);
 		e->bmpce_flags |= BMPCE_RBWRDY;
 		DEBUG_BMPCE(PLL_INFO, e, "rdref dec for RBW, !DATARDY");
-		aio_completion_try = 0;
 
 	} else {
 		e->bmpce_flags |= BMPCE_DATARDY;
 		DEBUG_BMPCE(PLL_INFO, e, "datardy via read_cb");
 		BMPCE_WAKE(e);
 
-//		psc_assert(psc_atomic32_read(
-//		    &e->bmpce_waitq->wq_nwaiters) == 0);
-
 		e->bmpce_waitq = NULL;
 		e->bmpce_owner = NULL;
 	}
@@ -1046,9 +889,6 @@
 	e->bmpce_flags &= ~BMPCE_AIOWAIT;
 
 	BMPCE_ULOCK(e);
-
-	if (aio_completion_try)
-		msl_bmpce_aio_process(e);
 }
 
 /**
@@ -1060,14 +900,14 @@
  */
 int
 msl_read_cb(struct pscrpc_request *rq, int rc,
-    struct pscrpc_async_args *args)
+    struct pscrpc_async_args *args, __unusedx int aio)
 {
 	struct slashrpc_cservice *csvc = args->pointer_arg[MSL_CBARG_CSVC];
 	struct psc_dynarray *a = args->pointer_arg[MSL_CBARG_BMPCE];
 	struct bmpc_ioreq *r = args->pointer_arg[MSL_CBARG_BIORQ];
 	struct bmap_pagecache_entry *e;
 	struct bmapc_memb *b;
-	int i, decrefd = 0;
+	int i;
 
 	b = r->biorq_bmap;
 
@@ -1087,18 +927,15 @@
 	DEBUG_BIORQ(rc ? PLL_ERROR : PLL_INFO, r, "rc=%d", rc);
 
 	DYNARRAY_FOREACH(e, i, a) {
-		if ((r->biorq_flags & BIORQ_AIOWAIT) &&
-		    (e->bmpce_flags & BMPCE_AIOWAIT) && !decrefd) {
-			/*
-			 * Call aio decref one time per-RPC but only if
-			 * a page in the RPC is marked AIO.
-			 */
-			msl_biorq_aio_decref(r);
-			decrefd = 1;
-		}
 		msl_bmpce_rpc_done(e, rc);
 	}
+	BIORQ_LOCK(r);
+	r->biorq_flags &= ~(BIORQ_INFL | BIORQ_SCHED);
+	BIORQ_ULOCK(r);
 
+	msl_biorq_complete_fsrq(r);
+	msl_biorq_destroy(r);
+
 	/*
 	 * Free the dynarray which was allocated in
 	 * msl_read_rpc_launch().
@@ -1129,12 +966,12 @@
 	if (rc == SLERR_AIOWAIT)
 		return (msl_req_aio_add(rq, msl_read_cb, args));
 
-	return (msl_read_cb(rq, rc, args));
+	return (msl_read_cb(rq, rc, args, 0));
 }
 
 int
 msl_readahead_cb(struct pscrpc_request *rq, int rc,
-    struct pscrpc_async_args *args)
+    struct pscrpc_async_args *args, __unusedx int aio)
 {
 	struct bmap_pagecache_entry *e,
 	    **bmpces = args->pointer_arg[MSL_CBARG_BMPCE];
@@ -1159,17 +996,17 @@
 
 		DEBUG_BMPCE(rc ? PLL_ERROR : PLL_INFO, e, "rc=%d", rc);
 
-		msl_bmpce_rpc_done(e, rc);
-
 		BMPC_LOCK(bmpc);
+
 		BMPCE_LOCK(e);
 		pll_remove(&bmpc->bmpc_pndg_ra, e);
-		bmpce_handle_lru_locked(e, bmpc, BIORQ_READ, 0);
-		if (!rc)
-			/* EIO's are always unlocked inside
-			 *   bmpce_handle_lru_locked()
-			 */
-			BMPCE_ULOCK(e);
+		if (rc)
+			e->bmpce_flags |= BMPCE_EIO;
+		else
+			e->bmpce_flags |= BMPCE_DATARDY;
+		msl_bmpce_complete_biorq(e);
+		bmpce_release_locked(e, bmpc);
+
 		BMPC_ULOCK(bmpc);
 	}
 
@@ -1194,7 +1031,7 @@
 	if (rc == SLERR_AIOWAIT)
 		return (msl_req_aio_add(rq, msl_readahead_cb, args));
 
-	return (msl_readahead_cb(rq, rc, args));
+	return (msl_readahead_cb(rq, rc, args, 0));
 }
 
 int
@@ -1262,7 +1099,7 @@
 }
 
 int
-msl_dio_cb(struct pscrpc_request *rq, int rc, struct pscrpc_async_args *args)
+msl_dio_cb(struct pscrpc_request *rq, int rc, struct pscrpc_async_args *args, int aio)
 {
 	//struct slashrpc_cservice *csvc = args->pointer_arg[MSL_CBARG_CSVC];
 	struct bmpc_ioreq *r = args->pointer_arg[MSL_CBARG_BIORQ];
@@ -1280,15 +1117,18 @@
 	mq = pscrpc_msg_buf(rq->rq_reqmsg, 0, sizeof(*mq));
 	psc_assert(mq);
 
-	DEBUG_BIORQ(PLL_INFO, r, "completed dio (op=%d) off=%u sz=%u rc=%d",
-	    op, mq->offset, mq->size, rc);
+	DEBUG_BIORQ(PLL_INFO, r, "dio complete (op=%d, aio=%d) off=%u sz=%u rc=%d",
+	    op, aio, mq->offset, mq->size, rc);
 
 	if (rc && !r->biorq_fsrqi->mfsrq_err)
 		r->biorq_fsrqi->mfsrq_err = rc;
 
-	if ((r->biorq_flags & BIORQ_AIOWAIT) && !msl_biorq_aio_decref(r))
-		msl_fsrq_complete(r->biorq_fsrqi);
+	if (aio && op == SRMT_WRITE)
+		msl_fsrqinfo_aioreadyset(r->biorq_fsrqi);
 
+	msl_biorq_complete_fsrq(r);
+	msl_biorq_destroy(r);
+
 	return (rc);
 }
 
@@ -1303,7 +1143,7 @@
 	if (rc == SLERR_AIOWAIT)
 		return (msl_req_aio_add(rq, msl_dio_cb, args));
 
-	return (msl_dio_cb(rq, rc, args));
+	return (msl_dio_cb(rq, rc, args, 0));
 }
 
 __static int
@@ -1382,6 +1222,10 @@
 			pscrpc_set_remove_req(r->biorq_rqset, rq);
 			goto error;
 		}
+		BIORQ_LOCK(r);
+		r->biorq_ref++;
+		DEBUG_BIORQ(PLL_INFO, r, "dio launch (ref=%d)", r->biorq_ref);
+		BIORQ_ULOCK(r);
 	}
 	/* Should be no need for a callback since this call is fully
 	 *   blocking.
@@ -1399,10 +1243,6 @@
 	case 0:
 		psc_iostats_intv_add((op == SRMT_WRITE ?
 		    &msl_diowr_stat : &msl_diord_stat), size);
-
-		msl_biorq_destroy(r);
-		break;
-
 	case -SLERR_AIOWAIT:
 	case -EKEYEXPIRED:
 	default:
@@ -1455,6 +1295,7 @@
 	 *   from being processed prematurely.
 	 */
 	BIORQ_LOCK(r);
+	r->biorq_ref++;
 	r->biorq_flags |= BIORQ_FLUSHRDY;
 	DEBUG_BIORQ(PLL_INFO, r, "BIORQ_FLUSHRDY");
 	psc_assert(psclist_conjoint(&r->biorq_lentry,
@@ -1599,8 +1440,7 @@
 
 		e->bmpce_flags |= BMPCE_EIO;
 		DEBUG_BMPCE(PLL_WARN, e, "set BMPCE_EIO");
-		bmpce_handle_lru_locked(e, bmap_2_bmpc(b), BIORQ_READ,
-		    0);
+		bmpce_release_locked(e, bmap_2_bmpc(b));
 
 		if (added)
 			bmap_op_done_type(b, BMAP_OPCNT_READA);
@@ -1721,6 +1561,12 @@
 		pscrpc_set_remove_req(r->biorq_rqset, rq);
 		goto error;
 	}
+
+	BIORQ_LOCK(r);
+	r->biorq_ref++;
+	DEBUG_BIORQ(PLL_INFO, r, "rpc launch (ref=%d)", r->biorq_ref);
+	BIORQ_ULOCK(r);
+
 	return (0);
 
  error:
@@ -1824,8 +1670,9 @@
 __static int
 msl_pages_prefetch(struct bmpc_ioreq *r)
 {
-	int sched = 0, rc = 0, npages = 0;
+	int i, sched = 0, rc = 0, waitflag, npages = 0;
 	struct bmap_pagecache_entry *e;
+	
 
 	npages = psc_dynarray_len(&r->biorq_pages);
 
@@ -1870,20 +1717,8 @@
 		r->biorq_flags |= BIORQ_SCHED;
 		BIORQ_ULOCK(r);
 	}
-	return (rc);
-}
-
-/**
- * msl_pages_blocking_load - Manage data prefetching activities.  This
- *	includes waiting on other threads to complete RPCs for data in
- *	which we're interested.
- */
-__static int
-msl_pages_blocking_load(struct bmpc_ioreq *r)
-{
-	struct bmap_pagecache_entry *e;
-	int rc = 0, i, aio_placed = 0;
-
+	if (rc)
+		return (rc);
 	/*
 	 * Wait for all read activities (include RBW) associated with the
 	 * bioreq to complete.
@@ -1925,66 +1760,48 @@
 			return (rc);
 	}
 
+	waitflag = BMPCE_DATARDY | BMPCE_EIO;
+	if (r->biorq_flags & BIORQ_READ)
+		waitflag |= BMPCE_AIOWAIT;
+
 	DYNARRAY_FOREACH(e, i, &r->biorq_pages) {
 		BMPCE_LOCK(e);
-		DEBUG_BMPCE(PLL_INFO, e, " ");
-
-		if (!biorq_is_my_bmpce(r, e)) {
-			/* For pages not owned by this request,
-			 *    wait for them to become DATARDY
-			 *    or to have failed.
-			 */
-			while (!(e->bmpce_flags &
-			    (BMPCE_DATARDY | BMPCE_EIO | BMPCE_AIOWAIT))) {
-				DEBUG_BMPCE(PLL_NOTIFY, e, "waiting");
-				BMPCE_WAIT(e);
-				BMPCE_LOCK(e);
-			}
+		if (biorq_is_my_bmpce(r, e)) {
+			BMPCE_ULOCK(e);
+			continue;
 		}
+		while (!(e->bmpce_flags & waitflag)) {
+			DEBUG_BMPCE(PLL_NOTIFY, e, "waiting");
+			BMPCE_WAIT(e);
+			BMPCE_LOCK(e);
+		}
+		if (e->bmpce_flags & BMPCE_AIOWAIT) {
+			psc_assert(r->biorq_flags & BIORQ_READ);
+			MFH_LOCK(r->biorq_fhent);
+			/*
+			 * 10/25/2012:
+			 *
+			 * This flag is used to determine whether we should
+			 * decrement mfsrq_ref on I/O completion. When is
+			 * the corresponding increment?
+			 */
+			BIORQ_LOCK(r);
+			r->biorq_flags |= BIORQ_AIOWAIT;
+			BIORQ_ULOCK(r);
 
-		/* If this a read request OR another thread is dealing
-		 *   with this bmpce then check.
-		 */
-		if ((r->biorq_flags & BIORQ_READ) ||
-		    !biorq_is_my_bmpce(r, e)) {
-			/* If there was an error, retry or give up. */
-			if (e->bmpce_flags & BMPCE_EIO) {
-				r->biorq_flags &= ~BIORQ_SCHED;
-				rc = -EAGAIN;
-			}
+			msl_fsrq_aiowait_tryadd_locked(e, r);
+			MFH_ULOCK(r->biorq_fhent);
 
-			if (rc == 0 && (e->bmpce_flags & BMPCE_AIOWAIT)) {
-				rc = -SLERR_AIOWAIT;
-				if (!aio_placed) {
-					MFH_LOCK(r->biorq_fhent);
-					/*
-					 * 10/25/2012:
-					 *
-					 * This flag is used to determine whether we should
-					 * decrement mfsrq_ref on I/O completion. When is
-					 * the corresponding increment?
-					 */
-					BIORQ_LOCK(r);
-					r->biorq_flags |= BIORQ_AIOWAIT;
-					BIORQ_ULOCK(r);
-
-					msl_fsrq_aiowait_tryadd_locked(e, r);
-					MFH_ULOCK(r->biorq_fhent);
-
-					OPSTAT_INCR(SLC_OPST_AIO_PLACED);
-					aio_placed = 1;
-				}
-			}
-
-			/* Read requests must have had their bmpce's
-			 *   put into DATARDY by now (i.e. all RPCs
-			 *   must have already been completed).
-			 *   Same goes for pages owned by other requests.
-			 */
-			psc_assert(e->bmpce_flags &
-			    (BMPCE_DATARDY | BMPCE_EIO | BMPCE_AIOWAIT));
+			rc = -SLERR_AIOWAIT;
+			OPSTAT_INCR(SLC_OPST_AIO_PLACED);
+			BMPCE_ULOCK(e);
+			break;
 		}
-
+		if (e->bmpce_flags & BMPCE_EIO) {
+			rc = -EIO;
+			BMPCE_ULOCK(e);
+			break;
+		}
 		BMPCE_ULOCK(e);
 	}
 
@@ -2153,7 +1970,6 @@
 		tsize  -= nbytes;
 	}
 	psc_assert(!tsize);
-	msl_biorq_destroy(r);
 
 	return (tbytes);
 }
@@ -2286,6 +2102,7 @@
 	DEBUG_BIORQ(PLL_INFO, r, "q=%p pos=%d", q, biorq_num);
 	psc_assert(!q->mfsrq_biorq[biorq_num]);
 	q->mfsrq_biorq[biorq_num] = r;
+	q->mfsrq_ref++;
 	MFH_ULOCK(r->biorq_fhent);
 }
 
@@ -2293,59 +2110,27 @@
 msl_fsrqinfo_init(struct pscfs_req *pfr, struct msl_fhent *mfh,
     char *buf, size_t size, off_t off, enum rw rw)
 {
-	int i;
 	struct msl_fsrqinfo *q = pfr->pfr_info;
 
-	if (!q) {
-		q = PSCALLOC(sizeof(*q));
+	psc_assert(!q);
+	q = PSCALLOC(sizeof(*q));
 
-		q->mfsrq_fh = mfh;
-		q->mfsrq_buf = buf;
-		q->mfsrq_size = size;
-		q->mfsrq_off = off;
-		q->mfsrq_rw = rw;
-		q->mfsrq_pfr = pfr;
+	q->mfsrq_fh = mfh;
+	q->mfsrq_buf = buf;
+	q->mfsrq_size = size;
+	q->mfsrq_off = off;
+	q->mfsrq_rw = rw;
+	q->mfsrq_pfr = pfr;
+	q->mfsrq_ref = 1;
+	q->mfsrq_len = 0;
 
-#if 0
-		/* avoid a theoretical race */
-		for (i = 0; i < MAX_BMAPS_REQ; i++)
-			q->mfsrq_biorq[i] = MSL_BIORQ_INIT;
-#endif
+	INIT_PSC_LISTENTRY(&q->mfsrq_lentry);
+	pfr->pfr_info = q;
+	if (rw == SL_READ)
+		OPSTAT_INCR(SLC_OPST_FSRQ_READ);
+	else
+		OPSTAT_INCR(SLC_OPST_FSRQ_WRITE);
 
-		INIT_PSC_LISTENTRY(&q->mfsrq_lentry);
-		pfr->pfr_info = q;
-		if (rw == SL_READ)
-			OPSTAT_INCR(SLC_OPST_FSRQ_READ);
-		else
-			OPSTAT_INCR(SLC_OPST_FSRQ_WRITE);
-	} else {
-		/*
-		 * A write request must wait for AIO to complete.
-		 */
-		psc_assert(q->mfsrq_fh == mfh &&
-			   q->mfsrq_buf == buf &&
-			   q->mfsrq_size == size &&
-			   q->mfsrq_off == off &&
-			   q->mfsrq_rw == rw &&
-			   q->mfsrq_pfr == pfr);
-
-		MFH_LOCK(mfh);
-		q->mfsrq_flags = MFSRQ_REISSUED;
-		q->mfsrq_reissue++;
-		MFH_ULOCK(mfh);
-		OPSTAT_INCR(SLC_OPST_FSRQ_REISSUE);
-
-		for (i = 0; i < MAX_BMAPS_REQ; i++) {
-			if (!q->mfsrq_biorq[i])
-				continue;
-
-			msl_biorq_destroy(q->mfsrq_biorq[i]);
-			q->mfsrq_biorq[i] = NULL;
-		}
-	}
-
-	psclog_info("q=%p nreissue=%d", q, q->mfsrq_reissue);
-
 	return (q);
 }
 
@@ -2404,7 +2189,7 @@
 	e = ((off + size) - 1) / SLASH_BMAP_SIZE;
 	nr = e - s + 1;
 	if (nr > MAX_BMAPS_REQ) {
-		rc = -EINVAL;
+		rc = EINVAL;
 		return (rc);
 	}
 
@@ -2413,6 +2198,7 @@
 	q = msl_fsrqinfo_init(pfr, mfh, buf, size, off, rw);
 
  restart:
+
 	rc = 0;
 	tsize = size;
 
@@ -2450,12 +2236,12 @@
 	tlen = MIN(SLASH_BMAP_SIZE - (size_t)roff, tsize);
 
 	/*
+	 * Step 1: build biorqs
+	 *
 	 * For each block range, get its bmap and make a request into its
 	 *  page cache.  This first loop retrieves all the pages.
 	 */
 	for (i = 0, bufp = buf; i < nr; i++) {
-		if (q->mfsrq_biorq[i])
-			goto load_next;
 
 		DEBUG_FCMH(PLL_INFO, f, "sz=%zu tlen=%zu off=%"PSCPRIdOFFT" "
 		    "roff=%"PSCPRIdOFFT" rw=%s", tsize, tlen, off, roff,
@@ -2486,42 +2272,23 @@
 			bmap_op_done(b);
 			goto retry_bmap;
 		}
+
 		/*
 		 * Re-relativize the offset if this request spans more
 		 * than 1 bmap.
 		 */
-		msl_biorq_build(q, b, bufp, i, roff - (i * SLASH_BMAP_SIZE),
-		    tlen, (rw == SL_READ) ? BIORQ_READ : BIORQ_WRITE);
-
-		bmap_op_done(b);
-		/*
-		 * If we are not doing direct I/O, launch read for read
-		 * requests and pre-read for unaligned write requests.
-		 */
 		r = q->mfsrq_biorq[i];
-
-		if (!(r->biorq_flags & BIORQ_DIO) &&
-		    (r->biorq_flags &
-		      (BIORQ_READ | BIORQ_RBWFP | BIORQ_RBWLP))) {
-			rc = msl_pages_prefetch(r);
-			if (rc) {
-				rc = msl_offline_retry(r);
-				r->biorq_flags |=
-				    (r->biorq_flags & BIORQ_READ) ?
-				    BIORQ_READFAIL : BIORQ_RBWFAIL;
-
-				msl_biorq_destroy(r);
-				q->mfsrq_biorq[i] = NULL;
-
-				if (rc)
-					goto retry_bmap;
-
-				rc = -EIO;
-				goto out;
-			}
+		if (r) {
+			bmap_op_done_type(r->biorq_bmap, BMAP_OPCNT_BIORQ);
+			r->biorq_bmap = b;
+			bmap_op_start_type(b, BMAP_OPCNT_BIORQ);
+		} else {
+			msl_biorq_build(q, b, bufp, i, roff - (i * SLASH_BMAP_SIZE),
+	    			tlen, (rw == SL_READ) ? BIORQ_READ : BIORQ_WRITE);
+			r = q->mfsrq_biorq[i];
 		}
-		BMAP_CLI_BUMP_TIMEO(b);
- load_next:
+
+		bmap_op_done(b);
 		roff += tlen;
 		tsize -= tlen;
 		bufp += tlen;
@@ -2529,154 +2296,66 @@
 	}
 
 	/*
+	 * Step 2: launch biorqs
+	 *
 	 * Note that the offsets used here are file-wise offsets not
 	 * offsets into the buffer.
 	 */
-	for (i = 0, tsize = 0; i < nr; i++) {
+	for (i = 0, tsize = 0; i < nr; i++, tsize += tlen) {
 		r = q->mfsrq_biorq[i];
 
-		if (r == MSL_BIORQ_COMPLETE)
-			continue;
-
-		/* Associate the biorq's with the mfh. */
-		pll_addtail(&mfh->mfh_biorqs, r);
-
 		tlen = r->biorq_len;
 
 		if (r->biorq_flags & BIORQ_DIO) {
 			rc = msl_pages_dio_getput(r);
-			if (rc == -SLERR_AIOWAIT) {
-				msl_fsrqinfo_aioset(q);
-				continue;
-			}
-			if (rc) {
+			if (rc && rc != -SLERR_AIOWAIT) {
 				pll_remove(&mfh->mfh_biorqs, r);
 				rc = msl_offline_retry(r);
 				if (rc) {
-					msl_biorq_destroy(r);
-					q->mfsrq_biorq[i] = NULL;
+					//msl_biorq_destroy(r);
+					//q->mfsrq_biorq[i] = NULL;
 					goto restart;
 				}
 				rc = -EIO;
 				goto out;
 			}
-		} else {
-			/* Block for page fault completion by this or
-			 *   other threads which may be working on pages
-			 *   which we need.
-			 */
-			rc = msl_pages_blocking_load(r);
-			if (rc == -SLERR_AIOWAIT) {
-				DEBUG_BIORQ(PLL_INFO, r, "SLERR_AIOWAIT");
-				msl_fsrqinfo_aioset(q);
-				continue;
-			}
+			continue;
+		}
+		if (r->biorq_flags & (BIORQ_READ | BIORQ_RBWFP | BIORQ_RBWLP)) {
+
+			rc = msl_pages_prefetch(r);
+
 			if (rc) {
+				pll_remove(&mfh->mfh_biorqs, r);
 				rc = msl_offline_retry(r);
-				if (rc) {
-					/*
-					 * The app wants to retry the
-					 * failed I/O.  What we must do
-					 * in this logic is tricky since
-					 * we don't want to re-lease the
-					 * bmap.  We hold a fake ref to
-					 * the bmap so it doesn't get
-					 * reclaimed until bmap_get()
-					 * gets its own ref.
-					 */
-					if (bref)
-						bmap_op_done_type(bref,
-						    BMAP_OPCNT_BIORQ);
-					bref = r->biorq_bmap;
-					bmap_op_start_type(bref,
-					    BMAP_OPCNT_BIORQ);
+				r->biorq_flags |=
+				    (r->biorq_flags & BIORQ_READ) ?
+				    BIORQ_READFAIL : BIORQ_RBWFAIL;
 
-					r->biorq_flags |=
-					    (r->biorq_flags & BIORQ_READ) ?
-					    BIORQ_READFAIL : BIORQ_RBWFAIL;
-
-					msl_biorq_destroy(r);
-					q->mfsrq_biorq[i] = NULL;
+				if (rc)
 					goto restart;
-				}
+
 				rc = -EIO;
 				goto out;
 			}
-
-			if (rw == SL_READ)
-				tlen = msl_pages_copyout(r);
-			else
-				tlen = msl_pages_copyin(r);
+			continue;
 		}
-
-		/* Not needed for AIO purposes.
-		 */
-		q->mfsrq_biorq[i] = MSL_BIORQ_COMPLETE;
-		tsize += tlen;
+		/* no RPC is needed */
+		msl_biorq_complete_fsrq(r);
 	}
-	/* Check for AIO in the fsrq prior to opening the fsrq for async
-	 *    operation.  Otherwise a race condition is possible where the
-	 *    async handler will unset the 'aio' flag, making this ioreq
-	 *    look like a success.  The 'rc' is not used since more than
-	 *    one BIORQ may be involved in this operation.
-	 */
-	if (msl_fsrqinfo_aioisset(q)) {
 
-		msl_fsrqinfo_readyset(q);
-		if (rw == SL_WRITE) {
-			/* Writes can't leave this function before completing.
-			 * Block here until rci.c tells us to proceed.
-			 */
-			msl_fsrqinfo_aioreadywait(q);
-			psc_assert(q->mfsrq_flags & MFSRQ_AIOREADY);
-
-			/*
-			 * Our sliod does not know this could be a DIO
-			 * request.  So we have to re-send the request
-			 * again if the first one got AIOWAIT. This can
-			 * be improved some day.
-			 *
-			 * This code only handles DIO request. Other write
-			 * requests are handled by msl_pages_blocking_load().
-			 */
-			msl_fsrqinfo_init(pfr, mfh, buf, size, off, rw);
-
-			goto restart;
-		}
-		rc = -SLERR_AIOWAIT;
-
-	} else {
-		rc = tsize;
-	}
-
  out:
 	if (bref)
 		bmap_op_done_type(bref, BMAP_OPCNT_BIORQ);
 
+	/*
+	 * Step 3: finish biorqs
+ 	 */
 	for (i = 0; i < nr; i++) {
 		r = q->mfsrq_biorq[i];
-
-		if (!r || r == MSL_BIORQ_COMPLETE)
-			continue;
-
-		BIORQ_LOCK(r);
-
-		if (!(r->biorq_flags & BIORQ_AIOWAIT)) {
-			/* Cleanup failed biorq's.  For successful ops,
-			 *   msl_biorq_destroy called from
-			 *   msl_pages_copy[in|out].
-			 */
-			r->biorq_flags |= BIORQ_BMAPFAIL;
-			BIORQ_ULOCK(r);
+		if (r)
 			msl_biorq_destroy(r);
-
-			q->mfsrq_biorq[i] = MSL_BIORQ_COMPLETE;
-			q->mfsrq_err = rc;
-
-		} else {
-			BIORQ_ULOCK(r);
-		}
 	}
-
-	return (rc);
+	msl_complete_fsrq(q);
+	return (0);
 }
Index: slash_nara/mount_slash/rpc_cli.c
===================================================================
--- slash_nara/mount_slash/rpc_cli.c	(revision 20044)
+++ slash_nara/mount_slash/rpc_cli.c	(working copy)
@@ -201,7 +201,7 @@
 
 		lc = &resm2rmci(resm)->rmci_async_reqs;
 		while ((car = lc_getnb(lc)) != NULL) {
-			car->car_cbf(NULL, ECONNRESET, &car->car_argv);
+			car->car_cbf(NULL, ECONNRESET, &car->car_argv, 1);
 
 			psclog_info("return car=%p car_id=%"PRIx64" q=%p",
 			    car, car->car_id, car->car_fsrqinfo);
Index: slash_nara/mount_slash/rci.c
===================================================================
--- slash_nara/mount_slash/rci.c	(revision 20044)
+++ slash_nara/mount_slash/rci.c	(working copy)
@@ -111,8 +111,6 @@
 		OPSTAT_INCR(SLC_OPST_READ_CB);
 		a = car->car_argv.pointer_arg[MSL_CBARG_BMPCE];
 
-		msl_fsrqinfo_readywait(car->car_fsrqinfo);
-
 		DYNARRAY_FOREACH(e, i, a) {
 			if (!mq->rc) {
 				iovs[i].iov_base = e->bmpce_base;
@@ -165,7 +163,6 @@
 
 	} else if (car->car_cbf == msl_dio_cb) {
 		OPSTAT_INCR(SLC_OPST_DIO_CB);
-		msl_fsrqinfo_readywait(car->car_fsrqinfo);
 
 		/* FixMe: Should wake up waiters regardless of results */
 		if (mq->rc)
@@ -184,11 +181,7 @@
 			MFH_LOCK(car->car_fsrqinfo->mfsrq_fh);
 			msl_fsrqinfo_state(car->car_fsrqinfo,
 			    MFSRQ_AIOWAIT, -1, 0);
-			msl_fsrqinfo_aioreadyset(car->car_fsrqinfo);
 			MFH_ULOCK(car->car_fsrqinfo->mfsrq_fh);
-
-			/* XXX this causes a callback not being called */
-			car->car_cbf = NULL;
 		}
 
 	} else {
@@ -200,7 +193,7 @@
 	 * cleanup can happen.
 	 */
 	if (car->car_cbf)
-		car->car_cbf(rq, mq->rc, &car->car_argv);
+		car->car_cbf(rq, mq->rc, &car->car_argv, 1);
 
 	psclog_info("return car=%p car_id=%"PRIx64" q=%p", car,
 	    car->car_id, car->car_fsrqinfo);
Index: slash_nara/mount_slash/bmpc.c
===================================================================
--- slash_nara/mount_slash/bmpc.c	(revision 20044)
+++ slash_nara/mount_slash/bmpc.c	(working copy)
@@ -79,8 +79,8 @@
 	INIT_PSC_LISTENTRY(&e->bmpce_lentry);
 	INIT_PSC_LISTENTRY(&e->bmpce_ralentry);
 	INIT_SPINLOCK(&e->bmpce_lock);
-	pll_init(&e->bmpce_pndgaios, struct msl_fsrqinfo,
-	    mfsrq_lentry, &e->bmpce_lock);
+	pll_init(&e->bmpce_pndgaios, struct bmpc_ioreq,
+	    biorq_png_lentry, &e->bmpce_lock);
 	e->bmpce_flags = BMPCE_NEW;
 	e->bmpce_base = base;
 	if (!e->bmpce_base)
@@ -109,8 +109,10 @@
 	while (!e) {
 		e = SPLAY_FIND(bmap_pagecachetree, &bmpc->bmpc_tree,
 		    &search);
-		if (e)
+		if (e) {
+    			psc_atomic32_inc(&e->bmpce_ref);
 			break;
+		}
 
 		if (e2 == NULL) {
 			BMPC_ULOCK(bmpc);
@@ -133,7 +135,6 @@
 		OPSTAT_INCR(SLC_OPST_BMPCE_PUT);
 		psc_pool_return(bmpcePoolMgr, e2);
 	}
-
 	return (e);
 }
 
@@ -141,134 +142,6 @@
 bmpce_release_locked(struct bmap_pagecache_entry *,
     struct bmap_pagecache *);
 
-/**
- * bmpce_handle_lru_locked - Handle LRU list membership of a page entry.
- * @e: entry
- * @bmpc: page cache
- * @op: READ or WRITE
- * @incref: 1 = increment, 0 = decrement
- */
-void
-bmpce_handle_lru_locked(struct bmap_pagecache_entry *e,
-    struct bmap_pagecache *bmpc, int op, int incref)
-{
-	psc_assert(op == BIORQ_WRITE || op == BIORQ_READ);
-
-	LOCK_ENSURE(&bmpc->bmpc_lock);
-	LOCK_ENSURE(&e->bmpce_lock);
-
-	DEBUG_BMPCE((e->bmpce_flags & BMPCE_EIO) ? PLL_WARN : PLL_INFO,
-	    e, "op=%d incref=%d", op, incref);
-
-	psc_assert(psc_atomic16_read(&e->bmpce_wrref) >= 0);
-	psc_assert(psc_atomic16_read(&e->bmpce_rdref) >= 0);
-
-	if (psc_atomic16_read(&e->bmpce_wrref)) {
-		psc_assert(!(e->bmpce_flags & BMPCE_LRU));
-		psc_assert(!pll_conjoint(&bmpc->bmpc_lru, e));
-
-	} else {
-		if (e->bmpce_flags & BMPCE_LRU)
-			psc_assert(pll_conjoint(&bmpc->bmpc_lru, e));
-	}
-
-	if (incref) {
-		PFL_GETTIMESPEC(&e->bmpce_laccess);
-
-		if (op == BIORQ_WRITE) {
-			if (e->bmpce_flags & BMPCE_LRU) {
-				pll_remove(&bmpc->bmpc_lru, e);
-				e->bmpce_flags &= ~BMPCE_LRU;
-			}
-			psc_atomic16_inc(&e->bmpce_wrref);
-
-		} else {
-			if (e->bmpce_flags & BMPCE_LRU) {
-				pll_remove(&bmpc->bmpc_lru, e);
-				pll_add_sorted(&bmpc->bmpc_lru, e,
-				    bmpce_lrusort_cmp1);
-			} else {
-				psc_assert(
-				   psc_atomic16_read(&e->bmpce_wrref) ||
-				   psc_atomic16_read(&e->bmpce_rdref) ||
-				   (e->bmpce_flags & BMPCE_READPNDG)  ||
-				   (e->bmpce_flags & BMPCE_DATARDY)   ||
-				   (e->bmpce_flags & BMPCE_INIT));
-			}
-
-			psc_atomic16_inc(&e->bmpce_rdref);
-		}
-
-	} else {
-		if (!(e->bmpce_flags & BMPCE_EIO)) {
-			if (e->bmpce_flags & BMPCE_READA &&
-			    !(e->bmpce_flags & BMPCE_DATARDY))
-				/*
-				 * A biorq may be failed while ref'ing
-				 * READA pages.
-				 */
-				psc_assert(
-				    psc_atomic16_read(&e->bmpce_rdref) > 1);
-			else
-				psc_assert(e->bmpce_flags & BMPCE_DATARDY);
-		}
-
-		if (op == BIORQ_WRITE) {
-			psc_assert(psc_atomic16_read(&e->bmpce_wrref) > 0);
-			psc_assert(!(e->bmpce_flags & BMPCE_LRU));
-			psc_atomic16_dec(&e->bmpce_wrref);
-
-		} else {
-			psc_assert(psc_atomic16_read(&e->bmpce_rdref) > 0);
-			psc_atomic16_dec(&e->bmpce_rdref);
-			if (!psc_atomic16_read(&e->bmpce_rdref))
-				e->bmpce_flags &= ~BMPCE_READPNDG;
-		}
-
-		if (!(psc_atomic16_read(&e->bmpce_wrref) ||
-		      psc_atomic16_read(&e->bmpce_rdref))) {
-			/* Last ref on an EIO page so remove it.
-			 */
-			if (e->bmpce_flags & BMPCE_EIO) {
-				DEBUG_BMPCE(PLL_DIAG, e,
-				    "freeing bmpce marked EIO");
-
-				if (e->bmpce_flags & BMPCE_READPNDG) {
-					e->bmpce_flags &= ~BMPCE_READPNDG;
-					psc_assert(e->bmpce_waitq);
-					BMPCE_WAKE(e);
-				}
-
-				bmpce_freeprep(e);
-				bmpce_release_locked(e, bmpc);
-				return;
-
-			} else if (!(e->bmpce_flags & BMPCE_LRU)) {
-				e->bmpce_flags &= ~BMPCE_READPNDG;
-				e->bmpce_flags |= BMPCE_LRU;
-				pll_add_sorted(&bmpc->bmpc_lru, e,
-					       bmpce_lrusort_cmp1);
-			}
-
-		} else if (e->bmpce_flags & BMPCE_EIO) {
-			/*
-			 * In cases where EIO is present the lock must
-			 * be freed no matter what.  This is because we
-			 * try to free the bmpce above, which when
-			 * successful, replaces the bmpce to the pool.
-			 */
-			BMPCE_WAKE(e);
-			BMPCE_ULOCK(e);
-		}
-	}
-
-	if (pll_nitems(&bmpc->bmpc_lru) > 0) {
-		e = pll_peekhead(&bmpc->bmpc_lru);
-		memcpy(&bmpc->bmpc_oldest, &e->bmpce_laccess,
-		    sizeof(struct timespec));
-	}
-}
-
 int
 bmpc_biorq_cmp(const void *x, const void *y)
 {
@@ -280,29 +153,47 @@
 		 * have ordering priority.
 		 */
 		return (CMP(b->biorq_len, a->biorq_len));
-	return (CMP(a->biorq_off, b->biorq_off));
+return (CMP(a->biorq_off, b->biorq_off));
 }
 
-__static void
-bmpce_release_locked(struct bmap_pagecache_entry *e,
+void
+bmpce_free(struct bmap_pagecache_entry *e,
     struct bmap_pagecache *bmpc)
 {
-	psc_assert(!psc_atomic16_read(&e->bmpce_rdref));
-	psc_assert(!psc_atomic16_read(&e->bmpce_wrref));
-	psc_assert(pll_empty(&e->bmpce_pndgaios));
-	psc_assert(e->bmpce_flags == BMPCE_FREEING);
-
 	DEBUG_BMPCE(PLL_INFO, e, "freeing");
 
 	psc_assert(SPLAY_REMOVE(bmap_pagecachetree, &bmpc->bmpc_tree, e));
-	if (pll_conjoint(&bmpc->bmpc_lru, e))
-		pll_remove(&bmpc->bmpc_lru, e);
 
 	OPSTAT_INCR(SLC_OPST_BMPCE_PUT);
 	bmpce_init(bmpcePoolMgr, e);
 	psc_pool_return(bmpcePoolMgr, e);
 }
 
+void
+bmpce_release_locked(struct bmap_pagecache_entry *e,
+    struct bmap_pagecache *bmpc)
+{
+	psc_atomic32_dec(&e->bmpce_ref);
+	if (psc_atomic32_read(&e->bmpce_ref) > 0) {
+		BMPCE_ULOCK(e);
+		return;
+	}
+	psc_assert(pll_empty(&e->bmpce_pndgaios));
+	psc_assert(!psc_atomic32_read(&e->bmpce_ref));
+
+	if (e->bmpce_flags & BMPCE_LRU)
+		pll_remove(&bmpc->bmpc_lru, e);
+
+	if (e->bmpce_flags & BMPCE_DATARDY) {
+		PFL_GETTIMESPEC(&e->bmpce_laccess);
+		e->bmpce_flags |= BMPCE_LRU;
+		pll_add(&bmpc->bmpc_lru, e);
+		BMPCE_ULOCK(e);
+		return;
+	}
+	bmpce_free(e, bmpc);
+}
+
 struct bmpc_ioreq *
 bmpc_biorq_new(struct msl_fsrqinfo *q, struct bmapc_memb *b, char *buf,
     int rqnum, uint32_t off, uint32_t len, int op)
@@ -317,14 +208,16 @@
 	INIT_PSC_LISTENTRY(&r->biorq_lentry);
 	INIT_PSC_LISTENTRY(&r->biorq_mfh_lentry);
 	INIT_PSC_LISTENTRY(&r->biorq_bwc_lentry);
+	INIT_PSC_LISTENTRY(&r->biorq_png_lentry);
 	INIT_SPINLOCK(&r->biorq_lock);
 
 	PFL_GETTIMESPEC(&r->biorq_issue);
 	timespecadd(&r->biorq_issue, &bmapFlushDefMaxAge,
 	    &r->biorq_expire);
 
-	r->biorq_off  = off;
-	r->biorq_len  = len;
+	r->biorq_off = off;
+	r->biorq_ref = 1;
+	r->biorq_len = len;
 	r->biorq_buf = buf;
 	r->biorq_bmap = b;
 	r->biorq_flags = op;
@@ -384,10 +277,9 @@
 		b = SPLAY_NEXT(bmap_pagecachetree, &bmpc->bmpc_tree, a);
 
 		BMPCE_LOCK(a);
-		bmpce_freeprep(a);
-		BMPCE_ULOCK(a);
-
-		bmpce_release_locked(a, bmpc);
+		psc_assert(a->bmpce_flags & BMPCE_LRU);
+		pll_remove(&bmpc->bmpc_lru, a);
+		bmpce_free(a, bmpc);
 	}
 	psc_assert(SPLAY_EMPTY(&bmpc->bmpc_tree));
 	psc_assert(pll_empty(&bmpc->bmpc_lru));
@@ -443,49 +335,15 @@
 	PLL_FOREACH_SAFE(e, tmp, &bmpc->bmpc_lru) {
 		BMPCE_LOCK(e);
 
-		psc_assert(!psc_atomic16_read(&e->bmpce_wrref));
-
-		if (psc_atomic16_read(&e->bmpce_rdref)) {
+		psc_assert(e->bmpce_flags & BMPCE_LRU);
+		if (psc_atomic32_read(&e->bmpce_ref)) {
 			DEBUG_BMPCE(PLL_INFO, e, "rd ref, skip");
 			BMPCE_ULOCK(e);
 			continue;
 		}
-
-		if (e->bmpce_flags & BMPCE_EIO) {
-			/* The thread who sets BMPCE_EIO will remove
-			 *   this page from the cache.
-			 */
-			DEBUG_BMPCE(PLL_WARN, e, "BMPCE_EIO, skip");
-			BMPCE_ULOCK(e);
-			continue;
-		}
-
-#if 0
-		timespecsub(&e->bmpce_laccess, &ts, &expire);
-
-		if (timespeccmp(&ts, &e->bmpce_laccess, <)) {
-			DEBUG_BMPCE(PLL_NOTICE, e,
-			    "expire=("PSCPRI_TIMESPEC") too recent, skip",
-			    PSCPRI_TIMESPEC_ARGS(&expire));
-
-			BMPCE_ULOCK(e);
-			break;
-
-		} else {
-			DEBUG_BMPCE(PLL_NOTICE, e,
-			    "freeing expire=("PSCPRI_TIMESPEC")",
-			    PSCPRI_TIMESPEC_ARGS(&expire));
-
-		}
-#else
-		DEBUG_BMPCE(PLL_NOTICE, e, "freeing last_access=("
-			    PSCPRI_TIMESPEC")",
-			    PSCPRI_TIMESPEC_ARGS(&e->bmpce_laccess));
-		bmpce_freeprep(e);
-		bmpce_release_locked(e, bmpc);
+		bmpce_free(e, bmpc);
 		if (++freed >= nfree)
 			break;
-#endif
 	}
 
 	/* Save CPU, assume that the head of the list is the oldest entry.
Index: slash_nara/mount_slash/main.c
===================================================================
--- slash_nara/mount_slash/main.c	(revision 20044)
+++ slash_nara/mount_slash/main.c	(working copy)
@@ -1474,7 +1474,8 @@
 
 	PLL_FOREACH(r, &mfh->mfh_biorqs) {
 		BIORQ_LOCK(r);
-		r->biorq_flags |= BIORQ_FORCE_EXPIRE;
+		if (!r->biorq_ref)
+			r->biorq_flags |= BIORQ_FORCE_EXPIRE;
 		DEBUG_BIORQ(PLL_INFO, r, "force expire");
 		BIORQ_ULOCK(r);
 	}
@@ -2300,13 +2301,8 @@
 
 	msfsthr(pscthr_get())->mft_failcnt = 1;
 	rc = msl_write(pfr, mfh, buf, size, off);
-	if (rc < 0) {
-		if (rc == -SLERR_AIOWAIT)
-			return;
-		rc = -rc;
+	if (rc)
 		goto out;
-	}
-	rc = 0;
 
 	FCMH_LOCK(f);
 	PFL_GETTIMESPEC(&ts);
@@ -2333,15 +2329,13 @@
 	}
 	FCMH_ULOCK(f);
 
-	MFH_LOCK(mfh);
-	mfh->mfh_nbytes_wr += size;
-	MFH_ULOCK(mfh);
-
  out:
+	if (rc) {
+		pscfs_reply_write(pfr, size, rc);
+		OPSTAT_INCR(SLC_OPST_FSRQ_WRITE_FREE);
+	}
 	DEBUG_FCMH(PLL_INFO, f, "write: buf=%p rc=%d sz=%zu "
 	    "off=%"PSCPRIdOFFT, buf, rc, size, off);
-	pscfs_reply_write(pfr, size, rc);
-	OPSTAT_INCR(SLC_OPST_FSRQ_WRITE_FREE);
 }
 
 void
@@ -2379,27 +2373,14 @@
 
 	msfsthr(pscthr_get())->mft_failcnt = 1;
 
-	len = msl_read(pfr, mfh, buf, size, off);
+	rc = msl_read(pfr, mfh, buf, size, off);
+ out:
 
-	/*
-	 * If this request will be finished asynchronously, e.g. in the
-	 * case of a archival storage system, do not tie up this fs
-	 * worker thread.
-	 */
-	if (len == -SLERR_AIOWAIT)
-		return;
-
-	if (len < 0)
-		rc = -len;
-	else {
-		MFH_LOCK(mfh);
-		mfh->mfh_nbytes_rd += len;
-		MFH_ULOCK(mfh);
+	if (rc) {
+		pscfs_reply_read(pfr, buf, len, rc);
+		OPSTAT_INCR(SLC_OPST_FSRQ_READ_FREE);
 	}
 
- out:
-	pscfs_reply_read(pfr, buf, len, rc);
-	OPSTAT_INCR(SLC_OPST_FSRQ_READ_FREE);
 	DEBUG_FCMH(PLL_INFO, f, "read (end): buf=%p rc=%d sz=%zu "
 	    "len=%zd off=%"PSCPRIdOFFT, buf, rc, size, len, off);
 }
Index: slash_nara/mount_slash/bmpc.h
===================================================================
--- slash_nara/mount_slash/bmpc.h	(revision 20044)
+++ slash_nara/mount_slash/bmpc.h	(working copy)
@@ -62,8 +62,7 @@
 struct timespec			bmapFlushDefMaxAge;
 
 struct bmap_pagecache_entry {
-	psc_atomic16_t		 bmpce_wrref;	/* pending write ops		*/
-	psc_atomic16_t		 bmpce_rdref;	/* pending read ops		*/
+	psc_atomic32_t		 bmpce_ref;	/* biorq and readahead refs     */
 	uint64_t		 bmpce_syncxid;	/* xid associated with sync op	*/
 	uint32_t		 bmpce_flags;	/* BMPCE_* flag bits		*/
 	uint32_t		 bmpce_off;	/* filewise, bmap relative	*/
@@ -151,13 +150,12 @@
 	    "bmpce@%p fl=%u:"BMPCE_FLAGS_FORMAT" "			\
 	    "o=%#x b=%p "						\
 	    "ts="PSCPRI_TIMESPEC" "					\
-	    "wr=%hu rd=%hu "						\
+	    "ref=%u "							\
 	    "owner=%p : " fmt,						\
 	    (b), (b)->bmpce_flags, DEBUG_BMPCE_FLAGS(b),		\
 	    (b)->bmpce_off, (b)->bmpce_base,				\
 	    PSCPRI_TIMESPEC_ARGS(&(b)->bmpce_laccess),			\
-	    psc_atomic16_read(&(b)->bmpce_wrref),			\
-	    psc_atomic16_read(&(b)->bmpce_rdref),			\
+	    psc_atomic32_read(&(b)->bmpce_ref),				\
 	    (b)->bmpce_owner, ## __VA_ARGS__)
 
 static __inline int
@@ -251,6 +249,7 @@
 
 struct bmpc_ioreq {
 	char				*biorq_buf;
+	int32_t				 biorq_ref;
 	/*
 	 * Note that a request may fall somewhere within a bmap. It might be not page aligned.
 	 */
@@ -266,6 +265,7 @@
 	struct psclist_head		 biorq_lentry;	/* chain on bmpc_pndg_biorqs	*/
 	struct psclist_head		 biorq_mfh_lentry; /* chain on file handle	*/
 	struct psclist_head		 biorq_bwc_lentry;
+	struct psclist_head		 biorq_png_lentry;
 	struct bmapc_memb		*biorq_bmap;	/* backpointer to our bmap	*/
 	struct pscrpc_request_set	*biorq_rqset;
 	struct psc_waitq		 biorq_waitq;	/* used by a bmpce */
@@ -296,6 +296,7 @@
 #define BIORQ_BMAPFAIL			(1 << 20)
 #define BIORQ_READFAIL			(1 << 21)
 #define BIORQ_PENDING			(1 << 22)
+#define BIORQ_WAIT			(1 << 23)
 
 #define BIORQ_LOCK(r)			spinlock(&(r)->biorq_lock)
 #define BIORQ_ULOCK(r)			freelock(&(r)->biorq_lock)
@@ -306,7 +307,7 @@
 #define DEBUG_BIORQ(level, b, fmt, ...)					\
 	psclogs((level), SLSS_BMAP, "biorq@%p "				\
 	    "fl=%#x:%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s "	\
-	    "o=%u l=%u r=%u buf=%p q=%p sliod=%x "			\
+	    "ref=%d o=%u l=%u r=%u buf=%p q=%p sliod=%x "		\
 	    "np=%d b=%p "						\
 	    "ex="PSCPRI_TIMESPEC" : "fmt,				\
 	    (b), (b)->biorq_flags,					\
@@ -333,7 +334,7 @@
 	    (b)->biorq_flags & BIORQ_BMAPFAIL		? "b" : "",	\
 	    (b)->biorq_flags & BIORQ_READFAIL		? "E" : "",	\
 	    (b)->biorq_flags & BIORQ_PENDING		? "p" : "",	\
-	    (b)->biorq_off, (b)->biorq_len, (b)->biorq_retries,		\
+	    (b)->biorq_ref, (b)->biorq_off, (b)->biorq_len, (b)->biorq_retries,		\
 	    (b)->biorq_buf, (b)->biorq_fsrqi, (b)->biorq_last_sliod,	\
 	    psc_dynarray_len(&(b)->biorq_pages), (b)->biorq_bmap,	\
 	    PSCPRI_TIMESPEC_ARGS(&(b)->biorq_expire), ## __VA_ARGS__)
@@ -355,20 +356,6 @@
 };
 
 static __inline void
-bmpce_freeprep(struct bmap_pagecache_entry *bmpce)
-{
-	LOCK_ENSURE(&bmpce->bmpce_lock);
-
-	psc_assert(!(bmpce->bmpce_flags & (BMPCE_FREEING | BMPCE_NEW)));
-	psc_assert(bmpce->bmpce_flags & (BMPCE_DATARDY | BMPCE_EIO));
-
-	psc_assert(!psc_atomic16_read(&bmpce->bmpce_rdref));
-	psc_assert(!psc_atomic16_read(&bmpce->bmpce_wrref));
-
-	bmpce->bmpce_flags = BMPCE_FREEING;
-}
-
-static __inline void
 bmpce_useprep(struct bmap_pagecache_entry *bmpce,
     struct bmpc_ioreq *biorq, struct psc_waitq *wq)
 {
@@ -376,9 +363,8 @@
 	psc_assert(psclist_disjoint(&bmpce->bmpce_lentry));
 	psc_assert(psclist_disjoint(&bmpce->bmpce_ralentry));
 	psc_assert(bmpce->bmpce_flags == BMPCE_NEW);
-	psc_assert(!psc_atomic16_read(&bmpce->bmpce_wrref));
-	psc_assert(!psc_atomic16_read(&bmpce->bmpce_rdref));
 
+	psc_atomic32_set(&bmpce->bmpce_ref, 1);
 	bmpce->bmpce_flags = BMPCE_INIT;
 	bmpce->bmpce_owner = biorq;
 	/*
@@ -403,10 +389,7 @@
 
 	DEBUG_BMPCE(PLL_DEBUG, bmpce, "op=%d off=%u", op, off);
 
-	if (op == BIORQ_READ)
-		psc_assert(psc_atomic16_read(&bmpce->bmpce_rdref) > 0);
-	else
-		psc_assert(psc_atomic16_read(&bmpce->bmpce_wrref) > 0);
+	psc_assert(psc_atomic32_read(&bmpce->bmpce_ref) > 0);
 
 	psc_assert(bmpce->bmpce_off == off);
 	ureqlock(&bmpce->bmpce_lock, locked);
@@ -447,8 +430,11 @@
 	 bmpce_lookup_locked(struct bmap_pagecache *, struct bmpc_ioreq *,
 	    uint32_t, struct psc_waitq *);
 void	 bmpce_handle_lru_locked(struct bmap_pagecache_entry *,
-	    struct bmap_pagecache *, int, int);
+	    struct bmap_pagecache *, int);
 
+void	 bmpce_release_locked(struct bmap_pagecache_entry *, 
+	    struct bmap_pagecache *);
+
 void	 bwc_release(struct bmpc_write_coalescer *);
 
 extern struct psc_poolmgr	*bmpcePoolMgr;
