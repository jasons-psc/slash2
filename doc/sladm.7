.\" $Id$
.\" %PSC_START_COPYRIGHT%
.\" -----------------------------------------------------------------------------
.\" Copyright (c) 2009-2011, Pittsburgh Supercomputing Center (PSC).
.\"
.\" Permission to use, copy, and modify this software and its documentation
.\" without fee for personal use or non-commercial use within your organization
.\" is hereby granted, provided that the above copyright notice is preserved in
.\" all copies and that the copyright and this permission notice appear in
.\" supporting documentation.  Permission to redistribute this software to other
.\" organizations or individuals is not permitted without the written permission
.\" of the Pittsburgh Supercomputing Center.  PSC makes no representations about
.\" the suitability of this software for any purpose.  It is provided "as is"
.\" without express or implied warranty.
.\" -----------------------------------------------------------------------------
.\" %PSC_END_COPYRIGHT%
.Dd April 21, 2011
.Dt SLADM 7
.ds volume PSC \- SLASH Administrator's Manual
.Os http://www.psc.edu/
.Sh NAME
.Nm sladm
.Nd
.Tn SLASH
administration guide
.Sh DESCRIPTION
.Tn SLASH
is a distributed network file system featuring:
.Pp
.Bl -bullet -compact -offset indent
.It
support for data multi residency at the file chunk level
.It
system managed data transfer
.It
inline checksum verification
.El
.Pp
This document describes the steps involving in creating and deploying a
.Tn SLASH
file system.
.Ss Creating a File System for SLASH Metadata
.Tn SLASH
uses
.Tn ZFS
for its backend metadata file system.
To create a new
.Tn ZFS
file system, launch the
.Xr zfs-fuse 8
daemon:
.Bd -literal -offset indent
# zfs-fuse
.Pp
.Ed
Next, create a
.Tn ZFS
pool with
.Xr zpool 8
for the backing file system used by the
.Tn SLASH
metadata server.
For example:
.Bd -literal -offset indent
# zpool create mypool sda		# single drive
# zpool create mypool mirror sda sdb	# two mirrored drives
.Ed
.Pp
To allow
.Tn ZFS
to load this file system, create a cache dump file:
.Bd -literal -offset indent
# zpool set cachefile=/mypool.zcf mypool
.Ed
.Pp
Before this file system can be used by the
.Tn SLASH
metadata server, it must be initialized by
.Xr slimmns_format 8 :
.Bd -literal -offset indent
# slimmns_format /mypool
.Ed
.Pp
Next, an on-disk table for persistent data storage
.Po for recovering
issued
.Tn I/O
write leases, for example
.Pc
must be created with
.Xr odtable 1 :
.Bd -literal -offset indent
# odtable -o -C /mypool/.slmd/bmap.odtab
.Ed
.Pp
Now that the metadata file system has been set up,
.Xr zfs-fuse 8
must be terminated before the
.Tn SLASH
metadata server can access it:
.Bd -literal -offset indent
# umount /mypool
# pkill zfs-fuse
.Ed
.Ss Metadata Server Po Ss MDS Pc
The metadata server
.Xr slashd 8
maintains a journal file for resuming interrupted operations.
This can be created with the
.Xr slmkjrnl 8
utility:
.Bd -literal -offset indent
# slmkjrnl -f
.Ed
.Pp
Now launch
.Xr slashd 8 :
.Bd -literal -offset indent
# slashd -p /mypool.zcf mypool
.Ed
.Pp
.Xr slmctl 8
can be used to control live operation of
.Xr slashd 8
once it is online.
.Ss Tn Ss I/O Ss Server
The
.Tn I/O
server
.Xr sliod 8
writes files resident in a
.Tn SLASH
network to the root of the directory specified by the
.Ic fsroot
.Xr slash.conf 5
option.
This directory must be initialized for use with
.Xr slimmns_format 8 :
.Bd -literal -offset indent
# slimmns_format -i fsroot
.Ed
.Pp
Next, ensure that the shared
.Tn SLASH
network daemon communication key has been installed on the machine.
The file defaults to
.Pa /var/lib/slash/authbuf.key
and will be generated automatically by
.Xr slashd 8
or manually with
.Xr slkeymgt 8 :
.Bd -literal -offset indent
# scp mdshost:/var/lib/slash/authbuf.key /var/lib/slash
.Ed
.Pp
Now launch
.Xr sliod 8 :
.Bd -literal -offset indent
# sliod md@SITE
.Ed
.Pp
.Xr slictl 8
can be used to control live operation of the
.Tn I/O
server once it is online.
.Ss Client Mount Daemon
To communicate on a
.Tn SLASH
network, the shared network daemon communication key must be installed
on the machine.
The file defaults to
.Pa /var/lib/slash/authbuf.key
and will be generated automatically by
.Xr slashd 8
or manually with
.Xr slkeymgt 8 :
.Bd -literal -offset indent
# scp mdshost:/var/lib/slash/authbuf.key /var/lib/slash
.Ed
.Pp
Now
.Xr mount_slash 8
may be used to mount a
.Tn SLASH
file system under a directory node on the local system:
.Bd -literal -offset indent
# mount_slash -U -M md@SITE -I io@SITE /myfs
.Ed
.Pp
.Xr msctl 8
can be used to control live operation of the client mount point once it
has been brought up.
.Sh CAVEATS
Running metadata and
.Tn I/O
servers on the same machine currently requires configuring each daemon
to listen on different addresses.
Furthermore, the network configuration must be such that each daemon can
access clients via the client destination network address.
.Pp
For example, setups where
.Xr slashd 8
residing on one network on
.Li eth0
reaches a client over a different client network address than
.Xr sliod 8
residing on a different network on
.Li eth1
will not work.
.Pp
The reason for this is because alternative
.Tn TCP
ports cannot be used for each of
.Xr slashd 8
and
.Xr sliod 8 ,
as
.Tn SLASH
utilizes the Lustre networking stack which does not easily
permit applications from connecting to multiple peers on differing
.Tn TCP
ports.
A single
.Tn TCP
port must be used globally for all daemons.
.El
.Sh SEE ALSO
.Xr odtable 1 ,
.Xr slash.conf 5 ,
.Xr pflenv 7 ,
.Xr mount_slash 8 ,
.Xr msctl 8 ,
.Xr slashd 8 ,
.Xr slictl 8 ,
.Xr slimmns 8 ,
.Xr sliod 8 ,
.Xr slkeymgt 8 ,
.Xr slmctl 8 ,
.Xr slmkjrnl 8 ,
.Xr zpool 8
