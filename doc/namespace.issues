03/19/2010
----------

Looks like the hide_vnode() on a local fuse mount is failing:

root@citron: ~$ tree -a /zhihui_slash2/ | head -20
/zhihui_slash2/
|-- .slfidns
|   |-- 0
|   |   |-- 0
|   |   |   |-- 0
|   |   |   |-- 1
|   |   |   |-- 2
|   |   |   |-- 3
|   |   |   |   |-- 0004000000003ac2
|   |   |   |   |-- 0004000000003ac7
|   |   |   |   |-- 0004000000003ac8
|   |   |   |   `-- 0004000000003eb4
|   |   |   |-- 4
|   |   |   |   |-- 000400000000468d
|   |   |   |   `-- 000400000000468e
|   |   |   |       `-- newfilehere
|   |   |   |-- 5
|   |   |   |-- 6
|   |   |   |-- 7
|   |   |   |-- 8


We probably can't present both namespaces to the use at the same time to avoid confusing people/shell.

We can do some trick to convert a directory link to a regular file. But ZFS is going to read
the znode on disk and find out it is really a directory. 

Right now, I have:

root@citron: ~$ ls -ali /zhihui_slash2/.slfidns/0/0/4/
total 39
  12 drwx--x--x  6 root root  6 Mar 19 14:56 .
   7 drwx--x--x 18 root root 18 Mar 19 11:04 ..
4382 drwxr-xr-x  4 root root  3 Mar 19 14:56 000400000000468d
4383 drwxr-xr-x  3 root root  3 Mar 19 15:25 000400000000468e
   ? ?---------  ? ?    ?     ?            ? /zhihui_slash2/.slfidns/0/0/4/000400000000468b	<-- bug here
   ? ?---------  ? ?    ?     ?            ? /zhihui_slash2/.slfidns/0/0/4/000400000000468c

We can avoid traverse the two namespaces this way:

yanovich@psc.edu: we knew this when we investigated using directory hardlinking
yanovich@psc.edu: we just have to use find -maxdepth 3 on the .slfidns

03/24/2010
----------

We did an almost rewrite of the FID cache, and I did some experiments with a new test.  The setup are as follows:

root@citron: ~/projects/slash_nara/slashd$ PSC_LOG_LEVEL=3 gdb ./slashd
(gdb) r -p ~/zhihui_slash2.cf zhihui_slash2 2>/local/mds.log


root@grapefruit: ~/projects/slash_nara/mount_slash$ PSC_LOG_LEVEL=3 SLASH_MDS_NID="citron@PSC" SLASH2_PIOS_ID="bessemer@PSC" gdb ./mount_slash
(gdb) r /slash2 2> /local/client.log



zhihui@grapefruit: ~/projects/slash_nara/tests/namespace$ ./namespace -o 100000 /slash2/zhihui/testdir/

......


Files = 00011542, dirs = 000075, ops = 00011616
Files = 00011547, dirs = 000075, ops = 00011621
Files = 00011552, dirs = 000075, ops = 00011626
Files = 00011557, dirs = 000075, ops = 00011631

Delete dir operations: 0
Delete file operations: 0
Create dir operations: 74
Create file operations: 11560

Total files: 11560, dirs: 75, ops: 11634
Time used to age the directory is 1100.000000

It is very slow until I pressed control+C to stop it.

Potential reasons for slowness:

(1) Logging
	
	(gdb) shell ls -al /local/mds.log 
	-rw-r--r-- 1 root root 118159248 Mar 24 10:25 /local/mds.log
	(gdb) shell ls -al /local/client.log
	-rw-r--r-- 1 root root 360103727 Mar 24 10:26 /local/client.log

(2) test program: it has to do a lot of small allocations to scan a directory. It also
    has to do stat() to avoid reuse a filename.

(3) FID cache issues: too many duplicate asserts.

04/01/2010
----------

As of this change, new fid cache code seems to be in shape, albeit slow:

zhihui@grapefruit: ~$ ./projects/slash_nara/tests/namespace/namespace  -o 1000000 /slash2/zhihui/testdir39

....

Files = 00165256, dirs = 001925, ops = 00408488
Files = 00165257, dirs = 001925, ops = 00408493
Files = 00165258, dirs = 001925, ops = 00408498
Files = 00165262, dirs = 001926, ops = 00408503
Files = 00165259, dirs = 001926, ops = 00408508
Files = 00165260, dirs = 001926, ops = 00408513
Operation interrupted by signal 2.				<-- press control+C

Delete dir operations: 36
Delete file operations: 120628
Create dir operations: 1961
Create file operations: 285888

Total files: 165260, dirs: 1926, ops: 408513
Time used to age the directory is 19105.000000 seconds.

04/14/2010
----------

Make sure that the zp_parent field always points to the parent in the regular namespace, not the
by-id namespace.  This fixes the issue of readdir returning the right ".." information.

This fix only affects directories. We should re-create the ZFS pool to make this change take effect.

04/21/2010
----------

I have planned to let each log file to have a constant number of log entries.  That makes it easy
to find the right file that contains a log entry given its update sequence number.

We also need to support aging of updates.  If an update is, say, 30 seconds old, it will be propagated
to other MDSes immediately before the current log file is filled.

Paul proposes a idea of using batch numbers.  Basically one batch is stored in one log file.  A
log file is closed after its capacity is reached or when its old entry is too old.

Correspondingly, we can store batch numbers in the progress table for each MDS.  The problem with
this idea is that we can have lots of small files.

The other problem concerns the receiving MDS.  If it crashes in the middle of applying a log,
how can we maintain atomicity?  Should be because

	(1) We never re-use SLASH ID - used to detect if a file is already created/deleted.
	(2) ZFS guarantees internal consistency

We do have to make sure that the a file or a directory exist in both namespace (by-name
and by-id).  ZFS can only make sure one link exists or not.

We may have to stored an update sequence number in the disk inode (like zp_gen in znode_phys,
but that's used by ZFS transaction internally I guess).

Another idea is to use a different SLASH ID for each rename (possibly keep the original ZFS 
inode number).  But this does not cover the case of chmod etc.

A generation number is the best way to cope with this.  Note that within the same batch of 
changes, the same file can be changed multiple times.  But we have to add more fields into
znode_phys.

For now, we can settle down with using the timestamp fields.  They are originating from the 
same site that owns a file.

05/13/2010
----------

Stuck on how to tie our journaling with ZFS transaction.  Anyway, the following is a way
to find out the currently open transaction group in ZFS:

int
zfs_txg_info(zfsvfs_t *zfsvfs, uint64_t *txg)
{
        tx_state_t *tx; 
        tx_cpu_t *tc; 
        dsl_pool_t *dp; 

        dp = dmu_objset_pool(zfsvfs->z_os);
        tx = &dp->dp_tx;
        tc = &tx->tx_cpu[CPU_SEQID];

        mutex_enter(&tc->tc_lock);
        *txg = tx->tx_open_txg;
        mutex_exit(&tc->tc_lock);
}

The above method has a problem because the open transaction group can change afterwards.

I am going to push the logging code further down into the VOP_XXX() functions. There are 
two benefits for this:

	(1) I only log after I am sure that the operation was a success.  As a result,
	    I only propapage namespace update when I am sure the operation was a success.

	(2) I also record the current tx group number into the log record. That
	    tell me positively if I need to replay a log entry in our journal or not.

I am sure that until I call dmu_tx_commit(), the transaction group of which the tranaction is 
a part of won't commit.  I can do our own logging before that.   In other words, our logging
happens before the corresponding ZFS transaction commits, so I won't miss any update. 

The ZFS intent log (ZIL) won't commit unless you call zil_commit() explicitly. Most often,
they just die in memory.

05/20/2010
----------

Currently, the code assumes that each namespace update needs one 512 byte log entry to log.  But 
for an operation such as a rename, we might need two log entries (max name length is 256 and we 
need two names plus some extra fields).  

The problem is that it is hard to make two log entries atomic (they might not even be next to 
each other).  For example, we need to propagate them at the same time to that the rename will 
be atomic on the receiving MDS.  We also need to change the underlying journaling and namespace 
logging code to allow chaining two log entries together.

To make things easier, we can separate a rename into at most three log operations even if they
could have been done atomically.  By the way, we have to do that anyway if the old and new parents
are managed by different sites.

Here is the relevant code in ZFS:

3347         if (tzp)        /* Attempt to remove the existing target */
3348                 error = zfs_link_destroy(tdl, tzp, tx, zflg, NULL);		<-- one log
3349 
3350         if (error == 0) {
3351                 error = zfs_link_create(tdl, szp, tx, ZRENAMING);			<-- one log
3352                 if (error == 0) {
3353                         szp->z_phys->zp_flags |= ZFS_AV_MODIFIED;
3354 
3355                         error = zfs_link_destroy(sdl, szp, tx, ZRENAMING, NULL);	<-- one log
3356                         ASSERT(error == 0);
3357 
3358                         zfs_log_rename(zilog, tx,
3359                             TX_RENAME | (flags & FIGNORECASE ? TX_CI : 0),
3360                             sdzp, sdl->dl_name, tdzp, tdl->dl_name, szp);
3361 
3362                         /* Update path information for the target vnode */
3363                         vn_renamepath(tdvp, ZTOV(szp), tnm, strlen(tnm));
3364                 }
3365         }
3366 
3367         dmu_tx_commit(tx);

It is interesting to note that they commit even if there might be an error (perhaps they should
asser that error == 0).

We can somehow justify this decision because eventually all log entries of a rename should be 
applied and the end result is the same.

Here is the code that implements this idea:

	if (tzp) {	/* Attempt to remove the existing target */
		error = zfs_link_destroy(tdl, tzp, tx, zflg, NULL);
		if (logfunc) {
			uint64_t txg;

			txg = dmu_tx_get_txg(tx);
			logfunc(ZTOV(tzp)->v_type != VDIR ? NS_OP_UNLINK : NS_OP_RMDIR, 
				txg, tdzp->z_phys->zp_s2id, 0, tzp->z_phys->zp_s2id, NULL, tnm, NULL);
		}
	}

	if (error == 0) {
		error = zfs_link_create(tdl, szp, tx, ZRENAMING);
		if (error == 0) {
			szp->z_phys->zp_flags |= ZFS_AV_MODIFIED;

			error = zfs_link_destroy(sdl, szp, tx, ZRENAMING, NULL);
			ASSERT(error == 0);
			if (logfunc) {
				uint64_t txg;
				struct srt_stat stat;
				vattr_t vattr;

				txg = dmu_tx_get_txg(tx);

				memset(&vattr, 0, sizeof(vattr_t));
				vattr.va_uid  = szp->z_phys->zp_uid;
				vattr.va_gid  = szp->z_phys->zp_gid;
				vattr.va_mode = szp->z_phys->zp_mode;
				ZFS_TIME_DECODE(&vattr.va_atime, szp->z_phys->zp_atime);
				ZFS_TIME_DECODE(&vattr.va_mtime, szp->z_phys->zp_mtime);
				ZFS_TIME_DECODE(&vattr.va_ctime, szp->z_phys->zp_ctime);
				
				zfs_vattr_to_stat(&stat, &vattr);

				txg = dmu_tx_get_txg(tx);
				/*
				 * A receiving MDS replays log entries in order.  We must remove
				 * the old target first so that the same fidlink can be removed
				 * and added back to point to the new target.  Note that the 
				 * slash ID remains the same during a rename.
				 */
				logfunc(ZTOV(szp)->v_type != VDIR ? NS_OP_UNLINK : NS_OP_RMDIR, 
					txg, sdzp->z_phys->zp_s2id, 0, szp->z_phys->zp_s2id, NULL, snm, NULL); 
				logfunc(ZTOV(szp)->v_type != VDIR ? NS_OP_CREATE : NS_OP_MKDIR, 
					txg, tdzp->z_phys->zp_s2id, 0, szp->z_phys->zp_s2id, &stat, tnm, NULL);
			}

			zfs_log_rename(zilog, tx,
			    TX_RENAME | (flags & FIGNORECASE ? TX_CI : 0),
			    sdzp, sdl->dl_name, tdzp, tdl->dl_name, szp);

			/* Update path information for the target vnode */
			vn_renamepath(tdvp, ZTOV(szp), tnm, strlen(tnm));
		}
	}

05/27/2010
----------

Suppose I do the following:

	mkdir zhihui1
	mv zhihui1 zhihui2

Whey replaying the first operation, the fidlink is created for zhihui1 based on its slash ID.
To replay the second operation, I am doing two things (assuming that zhihui2 does not already
exist yet) based on the idea outlined on 05/20/2010:

	(1) mkdir zhihui2
	(2) rmdir zhihui1

(1) will fail because it can't create a fidlink again for zhihui2, the same slash ID is already
used by zhihui1.  So perhaps I need to reverse the order of (1) and (2).


06/04/2010
----------

After I implemented the above method.  I did the following:

	(1) mkdir dir1 on client A connected to MDS A
	(2) stat dir1 on client B connected to MDS B.  You have to wait for a while before
	    it shows up.
	(3) watch -n 1 "stat dir2" on client B.  It returns "No such file or directory'.
	(4) mv dir1 dir2 on client A
	(5) Step (3) returns EIO now.

Paul can reproduce this problem with only one MDS.  After some study, Paul found out that the 
following code is probably the suspect:

 179 static struct dentry *fuse_lookup(struct inode *dir, struct dentry *entry,
 180                                   struct nameidata *nd)
 181 {
 182         int err;
 183         struct fuse_entry_out outarg;
 184         struct inode *inode = NULL;
 185         struct fuse_conn *fc = get_fuse_conn(dir);
 186         struct fuse_req *req;
 187 
 188         if (entry->d_name.len > FUSE_NAME_MAX)
 189                 return ERR_PTR(-ENAMETOOLONG);
 190 
 191         req = fuse_get_request(fc);
 192         if (!req)
 193                 return ERR_PTR(-EINTR);
 194 
 195         fuse_lookup_init(req, dir, entry, &outarg);
 196         request_send(fc, req);
 197         err = req->out.h.error;
 198         /* Zero nodeid is same as -ENOENT, but with valid timeout */
 199         if (!err && outarg.nodeid &&
 200             (invalid_nodeid(outarg.nodeid) || !valid_mode(outarg.attr.mode)))
 201                 err = -EIO;
 202         if (!err && outarg.nodeid) {
 203                 inode = fuse_iget(dir->i_sb, outarg.nodeid, outarg.generation,
 204                                   &outarg.attr);
 205                 if (!inode) {
 206                         fuse_send_forget(fc, req, outarg.nodeid, 1);
 207                         return ERR_PTR(-ENOMEM);
 208                 }
 209         }
 210         fuse_put_request(fc, req);
 211         if (err && err != -ENOENT)
 212                 return ERR_PTR(err);
 213 
 214         if (inode && dir_alias(inode)) {
 215                 iput(inode);
 216                 return ERR_PTR(-EIO);		<-- H E R E
 217         }

The test is done on tangerine. But the procedure works fine on wolverine.  Why?

zhihui@tangerine: ~$ uname -a
Linux tangerine 2.6.16-27-0.9_lustre-1.4.11customZestion_Oprofile #4 SMP Wed Sep 10 12:23:20 EDT 2008 x86_64 x86_64 x86_64 GNU/Linux

-bash-3.2$ uname -a
Linux wolverine.psc.edu 2.6.18-194.3.1.el5xen #1 SMP Thu May 13 13:49:53 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux

Looks like in the newer kernel version, if an alias of a directory is found, the FUSE kernel module just invalidates it
instead of returning EIO.

06/07/2010
----------

Looks like I need to solve the logging issue for symlink as well, which like rename, also needs two names.  In the case
of rename, I can break it into 2 or 3 logical operations.   But in the case of symlink, it is not possible to do so.

Guess I have to extend the current journaling/tiling code to deal with a multi-log entry transaction.

If we support multi-sector log entries, we have to overcome the tile boundary. We must make sure that a multi-sector log 
entry be sent in ONE RPC.

To get rid of tile boundaries, we could use a linked list of log entries.  That can lead to better use of memory.

An easy way is to limit the size of the two names in a rename or a symlink operation so that the whole operation
can be fit into a 512 byte log entry.
